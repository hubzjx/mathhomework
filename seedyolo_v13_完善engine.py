#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MVS ç›¸æœº + YOLO(Engine/ONNX/PT) + è¿‡çº¿è®¡æ•° + å¯†åº¦è¯†åˆ« + é‡Œç¨‹å¯¹é½(æ—¶é—´å¯¹é½) + é—¨æ§è¯†åˆ« + UIç•Œé¢
å¹¶æ”¯æŒï¼šæŠŠ"è¯†åˆ«åˆ°çš„ç§å­æ•°é‡"æŒ‰"åƒç²’é‡"æ¢ç®—ä¸ºå…‹é‡ï¼Œä½œä¸º EVENT ä¸‹å‘å­—æ®µä¹‹ä¸€ã€‚

æ–°å¢ï¼š
- è¿½è¸ªå™¨å¢å¼ºï¼šIOU + å¹³æ»‘ä¸­å¿ƒ + ä¸¢å¤±å®¹å¿ï¼Œå¯é€‰è®¡æ•°åŒºåŸŸ/æ–¹å‘çº¦æŸã€‚
- UART æ–­è¿é‡è¿ï¼šRX/TX éƒ½æ”¯æŒè‡ªåŠ¨é‡è¿ä¸çŠ¶æ€å‘Šè­¦ã€‚
- ç°ä»£åŒ–UIç•Œé¢ï¼šä¸‰é¡µè®¾è®¡ï¼ˆé…ç½®é¡µ+è§†é¢‘æ˜¾ç¤ºé¡µ+é•¿å›¾è¯†åˆ«é¡µï¼‰ï¼Œè‡ªåŠ¨é€‚é…å±å¹•
- å…¼å®¹æ€§æ”¹è¿›ï¼šæ›´å¥½åœ°æ”¯æŒ YOLO26 ç­‰æ–°æ¨¡å‹è¾“å‡ºæ ¼å¼
- æ–°å¢é•¿å›¾æ‹¼æ¥ä¸è¯†åˆ«ï¼š
    * UART æ”¶å‘å¼€å¯æ—¶ï¼šé€Ÿåº¦ >0 è‡ªåŠ¨æ‹¼æ¥ï¼›é€Ÿåº¦ â‰¤0 è‡ªåŠ¨åœæ­¢å¹¶æ•´ä½“ YOLO è¯†åˆ«ã€‚
    * UART æ”¶å‘å…³é—­æ—¶ï¼šé€šè¿‡å¿«æ·é”®æˆ–æŒ‰é’®æ‰‹åŠ¨å¼€å§‹/ç»“æŸæ‹¼æ¥ï¼Œç»“æŸåæ•´ä½“ YOLO è¯†åˆ«ã€‚
    * åŸå§‹é•¿å›¾ä¸è¯†åˆ«ç»“æœä¿å­˜åˆ°åŒä¸€å­ç›®å½•ï¼ˆæŒ‰å¹´æœˆæ—¥æ—¶åˆ†ç§’å‘½åï¼‰ï¼Œä¿å­˜æ ¹ç›®å½•å¯é…ç½®ã€‚
- æ–°å¢æˆªå±åŠŸèƒ½ï¼šæˆªå–ç¨‹åºå…¨å±ç•Œé¢ï¼Œä¿å­˜è·¯å¾„å¯é…ç½®

ä¿®æ”¹ï¼š
- ROIè¯†åˆ«é€»è¾‘ï¼šå¯ç”¨è¿‡çº¿è®¡æ•°æ—¶åªè¯†åˆ«ROIåŒºåŸŸï¼Œä¸å¯ç”¨æ—¶å…¨å±è¯†åˆ«
- è®¡æ•°çº¿å‚æ•°åŒ–ï¼šè®¡æ•°çº¿ä½ç½®ä»ä¸Šåˆ°ä¸‹ç”¨ç™¾åˆ†æ¯”å‚æ•°è®¾ç½®ï¼ˆå¦‚5%ã€17%ï¼‰
- ROIè‡ªåŠ¨è®¡ç®—ï¼šæ ¹æ®è®¡æ•°çº¿ä½ç½®å’Œä¸Šä¸‹æ‰©å±•åƒç´ æ•°è‡ªåŠ¨è®¡ç®—ROIåŒºåŸŸ
- UIæ˜¾ç¤ºè°ƒæ•´ï¼šè§†é¢‘å·¦ä¸Šè§’ä¸å†æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ï¼Œåªåœ¨ç³»ç»ŸçŠ¶æ€é¡µæ˜¾ç¤º
- TensorRT 10.x APIå…¼å®¹æ€§ï¼šæ ¹æ®TensorRTç‰ˆæœ¬è‡ªé€‚åº”é€‰æ‹©æ‰§è¡Œæ–¹æ³•
"""

import os
import sys
import cv2
import time
import math
import json
import struct
import threading
import queue
import platform
from collections import deque
from dataclasses import dataclass
from datetime import datetime
import numpy as np
from ctypes import *

# ===== UI åº“ =====
try:
    from PyQt5.QtWidgets import (QApplication, QMainWindow, QWidget, QVBoxLayout, QHBoxLayout, 
                                 QTabWidget, QGroupBox, QLabel, QPushButton, QComboBox, 
                                 QSpinBox, QDoubleSpinBox, QCheckBox, QLineEdit, QTextEdit,
                                 QGridLayout, QSplitter, QScrollArea, QFrame, QSizePolicy,
                                 QMessageBox, QProgressBar, QSlider, QFileDialog)
    from PyQt5.QtCore import Qt, QTimer, pyqtSignal, QThread, QSize, QRect
    from PyQt5.QtGui import QImage, QPixmap, QFont, QIcon, QPalette, QColor, QPainter, QPen
    PYQT_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ PyQt5ä¸å¯ç”¨: {e}")
    print("è¯·å®‰è£…: pip install PyQt5")
    PYQT_AVAILABLE = False

# ===== MVS SDK =====
sys.path.append("/opt/MVS/Samples/aarch64/Python/MvImport")
from MvCameraControl_class import *  # noqa

# ===== å¯é€‰ï¼šä¸²å£ =====
try:
    import serial
    SERIAL_AVAILABLE = True
except Exception:
    SERIAL_AVAILABLE = False

# ===== å¯é€‰ï¼šYOLOv5 (ä»…ç”¨äº.pt èµ° yolov5 ä»£ç è·¯å¾„æ—¶) =====
YOLOV5_CODE_AVAILABLE = False
try:
    sys.path.append('/home/nvidia/Desktop/yolov5')
    from models.common import DetectMultiBackend
    from utils.general import non_max_suppression, scale_boxes
    from utils.augmentations import letterbox
    YOLOV5_CODE_AVAILABLE = True
except Exception:
    YOLOV5_CODE_AVAILABLE = False

# ===== PyTorch (ç”¨äº.pt) =====
TORCH_AVAILABLE = False
try:
    import torch
    TORCH_AVAILABLE = True
except Exception:
    TORCH_AVAILABLE = False

# ===== TensorRT (ç”¨äº.engine) =====
TRT_AVAILABLE = False
try:
    import tensorrt as trt
    import pycuda.driver as cuda
    import pycuda.autoinit  # noqa: F401
    TRT_AVAILABLE = True
except Exception:
    TRT_AVAILABLE = False

# ==========================
# é…ç½®åŒº
# ==========================
SEED_TKW_GRAMS = 40.0  # åƒç²’é‡ï¼ˆg/1000ç²’ï¼‰â€”â€”å¯æ›´æ”¹
DEFAULT_MODEL_PATH = "/home/nvidia/Desktop/yolov5/runs/train/1-22-26sbest.onnx"
MODEL_CANDIDATES = [
    "yolov12sbest.engine",
    "yolov12sbest.onnx",
    "yolov12sbest.pt",
    "yolov5s.pt",
    "yolov5s.onnx",
    "yolov5s.engine",
    "yolo26s.onnx",        # æ·»åŠ YOLO26æ¨¡å‹æ”¯æŒ
    "yolo26s.engine",
    "yolo26s.pt",
]

# ä¸²å£é…ç½®ï¼ˆæ ¹æ®å®é™…ä¿®æ”¹ï¼‰
UART_PORT = "/dev/ttyUSB0"
UART_BAUD = 921600
UART_RETRY_SEC = 2.0

# æ ¸å¿ƒæ¿ CTRL å¸§ç±»å‹
CTRL_MSG_TYPE = 0x01

# Jetson EVENT å¸§ç±»å‹
EVENT_MSG_TYPE = 0x10
EVENT_TYPE_LOW_DENSITY_SEG = 0x01

# é—¨æ§ï¼ˆæ­£å‘å³å¼€ï¼›éæ­£å‘æˆ–è¿‡æœŸå³å…³ï¼‰
V_ON = 0      # ä¿ç•™å­—æ®µï¼Œç°é€»è¾‘ä¸ä¾èµ–é˜ˆå€¼
V_OFF = 0     # ä¿ç•™å­—æ®µï¼Œç°é€»è¾‘ä¸ä¾èµ–é˜ˆå€¼
GATE_MAX_AGE = 0.5  # sï¼ŒCTRL æ•°æ®è¶…è¿‡è¯¥å¹´é¾„åˆ™ gate=false

CTRL_BUFFER_SECONDS = 10.0

# å¯†åº¦è¯†åˆ«å‚æ•°
DENSITY_ENABLED_DEFAULT = True
DENSITY_MAP_SHOW_DEFAULT = False
DENSITY_GRID_COLS = 16
DENSITY_GRID_ROWS = 6
LOW_DENSITY_RATIO = 0.35
LOW_DENSITY_MIN_FRAMES = 3
RECOVER_MIN_FRAMES = 3
MIN_DETS_FOR_DENSITY = 3  # å°‘äºè¯¥æ£€æµ‹æ•°ä¸åˆ¤å®šä½å¯†åº¦

# ç¼“å­˜æ–‡ä»¶ï¼ˆç­‰å¾…ä¸‹ä¸€æ­¥ä¸‹å‘ï¼Œæˆ–ä¹Ÿå¯è¾¹ç¼“å­˜è¾¹ä¸‹å‘ï¼‰
EVENT_CACHE_FILE = "low_density_segments.jsonl"
EVENT_MERGE_GAP_MM = 80
CACHE_QUEUE_MAX = 2000
CACHE_FLUSH_INTERVAL = 1.0  # s
CACHE_ROTATE_LINES = 200000  # è¶…è¿‡åˆ™è½®è½¬
CACHE_ROTATE_KEEP = 5  # æœ€å¤šä¿ç•™ 5 ä¸ªå†å²æ–‡ä»¶

# UIç›¸å…³é…ç½®
UI_UPDATE_INTERVAL = 30  # ms
VIDEO_DISPLAY_FPS = 30   # è§†é¢‘æ˜¾ç¤ºå¸§ç‡

# æ£€æµ‹å™¨é…ç½®
USE_NMS_FOR_YOLO26 = True  # å¯¹äºYOLO26ç«¯åˆ°ç«¯æ¨¡å‹ï¼Œå¯è®¾ä¸ºFalse
YOLO26_CONF_THRES = 0.15   # YOLO26ä¸“ç”¨ç½®ä¿¡åº¦é˜ˆå€¼
MAX_DETECTIONS = 20000     # æœ€å¤§æ£€æµ‹æ•°é‡é™åˆ¶

# EVENT å‘é€é˜Ÿåˆ—
EVENT_QUEUE_MAX = 2000

# é•¿å›¾æ‹¼æ¥é…ç½®
DEFAULT_SAVE_DIR = "/home/nvidia/Desktop/yolov5/captures"
DEFAULT_HOTKEY_START = "S"
DEFAULT_HOTKEY_STOP = "E"
MAX_LONG_FRAMES = 400           # é˜²æ­¢æ— é™å¢é•¿
MIN_HEIGHT_FOR_SAVE = 50        # å°‘äºè¯¥åƒç´ é«˜åº¦ä¸ä¿å­˜

# è®¡æ•°çº¿ä½ç½®å‚æ•°ï¼ˆä»ä¸Šåˆ°ä¸‹ç™¾åˆ†æ¯”ï¼‰
COUNT_LINE_PERCENT_DEFAULT = 5.0  # é»˜è®¤5%
COUNT_LINE_TOP_EXTEND_DEFAULT = 100  # å‘ä¸Šæ‰©å±•åƒç´ æ•°
COUNT_LINE_BOTTOM_EXTEND_DEFAULT = 100  # å‘ä¸‹æ‰©å±•åƒç´ æ•°

# ç”»é¢ä¸‹é‡‡æ ·å‚æ•°
DOWNSAMPLE_RATIO_DEFAULT = 1.0   # é»˜è®¤ä¸ä¸‹é‡‡æ ·
DOWNSAMPLE_OPTIONS = [1.0, 0.75, 0.5, 0.25]  # ä¸‹é‡‡æ ·é€‰é¡¹

# ===== CRC16 (CCITT-FALSE) =====
def crc16_ccitt_false(data: bytes, poly=0x1021, init=0xFFFF) -> int:
    crc = init
    for b in data:
        crc ^= (b << 8)
        for _ in range(8):
            crc = ((crc << 1) ^ poly) & 0xFFFF if (crc & 0x8000) else (crc << 1) & 0xFFFF
    return crc & 0xFFFF


# ===== ç§å­é‡é‡æ¢ç®— =====
def seed_count_to_grams(seed_count: int, tkw_grams: float) -> float:
    """æ ¹æ®åƒç²’é‡å°†æ£€æµ‹åˆ°çš„seedæ•°é‡æ¢ç®—ä¸ºå…‹é‡ï¼ˆgï¼‰ã€‚"""
    if seed_count <= 0:
        return 0.0
    return float(seed_count) * (float(tkw_grams) / 1000.0)


def grams_to_mg_u32(grams: float) -> int:
    """æŠŠå…‹é‡è½¬æ¢ä¸ºæ¯«å…‹å¹¶ç”¨ uint32 è¡¨ç¤ºï¼ˆé¿å…æµ®ç‚¹ä¼ è¾“ï¼‰ã€‚"""
    mg = int(round(max(0.0, grams) * 1000.0))
    return max(0, min(0xFFFFFFFF, mg))


# ===== æ§åˆ¶æ•°æ®ç»“æ„ä¸å¯¹é½ =====
@dataclass
class CtrlSample:
    t_rx_host: float
    t_ctrl_us: int
    s_mm: int
    v_mmps: int


class CtrlBuffer:
    def __init__(self, keep_seconds=10.0):
        self.keep_seconds = keep_seconds
        self.buf = deque()
        self.lock = threading.Lock()
        self._time_map_inited = False
        self.a = None
        self.b = None

    def add(self, sample: CtrlSample):
        with self.lock:
            self.buf.append(sample)
            self._trim_locked()

            if len(self.buf) >= 2:
                s2 = self.buf[-1]
                s1 = self.buf[-2]
                dt_ctrl = (s2.t_ctrl_us - s1.t_ctrl_us) / 1e6
                dt_host = (s2.t_rx_host - s1.t_rx_host)
                # å¼‚å¸¸è¿‡æ»¤ï¼šdt_ctrl å¤ªå°æˆ–è´Ÿå€¼ç›´æ¥ä¸¢å¼ƒæ‹Ÿåˆ
                if dt_ctrl > 1e-4 and dt_host > 0:
                    a = dt_host / dt_ctrl
                    b = s2.t_rx_host - a * (s2.t_ctrl_us / 1e6)
                    # è¿‡æ»¤ç¦»ç¾¤çš„ aï¼šè‹¥å˜åŒ–è¿‡å¤§åˆ™å¿½ç•¥
                    if self.a is None or abs(a - self.a) / max(1e-9, abs(self.a)) < 0.2:
                        if self.a is None:
                            self.a, self.b = a, b
                        else:
                            self.a = 0.9 * self.a + 0.1 * a
                            self.b = 0.9 * self.b + 0.1 * b
                        self._time_map_inited = True

    def _trim_locked(self):
        now = time.monotonic()
        while self.buf and (now - self.buf[0].t_rx_host) > self.keep_seconds:
            self.buf.popleft()

    def get_latest(self):
        with self.lock:
            return self.buf[-1] if self.buf else None

    def gate_enabled(self, v_on=V_ON, v_off=V_OFF, prev_state=False, max_age=GATE_MAX_AGE):
        latest = self.get_latest()
        if latest is None:
            return False
        age = time.monotonic() - latest.t_rx_host
        if age > max_age:
            return False
        v = latest.v_mmps
        # é€Ÿåº¦ä¸ºæ­£å°±å¼€ï¼Œé›¶/è´Ÿå°±å…³
        return v > 0

    def query_s_at_host_time(self, t_cap_host: float):
        with self.lock:
            if len(self.buf) < 2:
                return None, None, None

            if self._time_map_inited and self.a is not None and self.b is not None:
                if abs(self.a) < 1e-9:
                    return None, None, None
                t_ctrl_target_us = int(((t_cap_host - self.b) / self.a) * 1e6)

                prev = None
                for cur in self.buf:
                    if cur.t_ctrl_us >= t_ctrl_target_us:
                        if prev is None:
                            age = t_cap_host - cur.t_rx_host
                            if age > self.keep_seconds:
                                return None, None, None
                            return cur.s_mm, cur.v_mmps, age
                        t1, t2 = prev.t_ctrl_us, cur.t_ctrl_us
                        if t2 == t1:
                            age = t_cap_host - cur.t_rx_host
                            if age > self.keep_seconds:
                                return None, None, None
                            return cur.s_mm, cur.v_mmps, age
                        alpha = (t_ctrl_target_us - t1) / (t2 - t1)
                        s = int(round(prev.s_mm + alpha * (cur.s_mm - prev.s_mm)))
                        v = int(round(prev.v_mmps + alpha * (cur.v_mmps - prev.v_mmps)))
                        age = t_cap_host - (prev.t_rx_host + alpha * (cur.t_rx_host - prev.t_rx_host))
                        if age > self.keep_seconds:
                            return None, None, None
                        return s, v, age
                    prev = cur

                last = self.buf[-1]
                age = t_cap_host - last.t_rx_host
                if age > self.keep_seconds:
                    return None, None, None
                return last.s_mm, last.v_mmps, age

            # fallbackï¼šç”¨ t_rx_host
            prev = None
            for cur in self.buf:
                if cur.t_rx_host >= t_cap_host:
                    if prev is None:
                        age = t_cap_host - cur.t_rx_host
                        if age > self.keep_seconds:
                            return None, None, None
                        return cur.s_mm, cur.v_mmps, age
                    t1, t2 = prev.t_rx_host, cur.t_rx_host
                    if t2 == t1:
                        age = t_cap_host - cur.t_rx_host
                        if age > self.keep_seconds:
                            return None, None, None
                        return cur.s_mm, cur.v_mmps, age
                    alpha = (t_cap_host - t1) / (t2 - t1)
                    s = int(round(prev.s_mm + alpha * (cur.s_mm - prev.s_mm)))
                    v = int(round(prev.v_mmps + alpha * (cur.v_mmps - prev.v_mmps)))
                    age = t_cap_host - (t1 + alpha * (t2 - t1))
                    if age > self.keep_seconds:
                        return None, None, None
                    return s, v, age
                prev = cur

            last = self.buf[-1]
            age = t_cap_host - last.t_rx_host
            if age > self.keep_seconds:
                return None, None, None
            return last.s_mm, last.v_mmps, age


# ===== UART æ¥æ”¶çº¿ç¨‹ï¼ˆCTRLï¼‰ æ”¯æŒæ–­è¿é‡è¿ =====
class UartCtrlReceiver(threading.Thread):
    def __init__(self, port, baud, ctrl_buf: CtrlBuffer, retry_sec=UART_RETRY_SEC):
        super().__init__(daemon=True)
        self.port = port
        self.baud = baud
        self.ctrl_buf = ctrl_buf
        self.retry_sec = retry_sec
        self.stop_flag = threading.Event()
        self.ser = None

    def stop(self):
        self.stop_flag.set()
        try:
            if self.ser:
                self.ser.close()
        except Exception:
            pass

    def _open(self):
        if not SERIAL_AVAILABLE:
            print("âš ï¸  pyserial ä¸å¯ç”¨ï¼šæ— æ³•æ¥æ”¶æ ¸å¿ƒæ¿ CTRL æ•°æ®ã€‚")
            return False
        try:
            self.ser = serial.Serial(self.port, self.baud, timeout=0.2)
            self.ser.reset_input_buffer()
            print(f"âœ… UART å·²æ‰“å¼€(CTRL RX): {self.port} @ {self.baud}")
            return True
        except Exception as e:
            print(f"âš ï¸  UART æ‰“å¼€å¤±è´¥: {e}, å°†åœ¨ {self.retry_sec}s åé‡è¯•")
            return False

    def run(self):
        buf = bytearray()
        while not self.stop_flag.is_set():
            if self.ser is None or (not self.ser.is_open):
                if not self._open():
                    time.sleep(self.retry_sec)
                    continue

            try:
                chunk = self.ser.read(512)
                if chunk:
                    buf.extend(chunk)
                else:
                    continue

                while True:
                    sof_idx = buf.find(b'\xAA\x55')
                    if sof_idx < 0:
                        if len(buf) > 4096:
                            buf = buf[-16:]
                        break
                    if sof_idx > 0:
                        buf = buf[sof_idx:]

                    # æœ€å°é•¿åº¦ï¼š2+1+1+18+2 = 24
                    if len(buf) < 24:
                        break

                    msg_type = buf[2]
                    payload_len = buf[3]
                    frame_len = 2 + 1 + 1 + payload_len + 2
                    if len(buf) < frame_len:
                        break

                    frame = bytes(buf[:frame_len])
                    buf = buf[frame_len:]

                    if msg_type != CTRL_MSG_TYPE:
                        continue

                    recv_crc = struct.unpack_from('<H', frame, frame_len - 2)[0]
                    calc_crc = crc16_ccitt_false(frame[:-2])
                    if recv_crc != calc_crc:
                        continue

                    if payload_len < 18:
                        continue

                    seq = struct.unpack_from('<H', frame, 4)[0]
                    t_ctrl_us = struct.unpack_from('<Q', frame, 6)[0]
                    s_mm = struct.unpack_from('<I', frame, 14)[0]
                    v_mmps = struct.unpack_from('<i', frame, 18)[0]

                    sample = CtrlSample(
                        t_rx_host=time.monotonic(),
                        t_ctrl_us=int(t_ctrl_us),
                        s_mm=int(s_mm),
                        v_mmps=int(v_mmps)
                    )
                    self.ctrl_buf.add(sample)

            except Exception as e:
                print(f"âš ï¸  UART RX å¼‚å¸¸: {e}, å°†é‡è¿")
                try:
                    if self.ser:
                        self.ser.close()
                except Exception:
                    pass
                self.ser = None
                time.sleep(self.retry_sec)


# ===== UART ä¸‹å‘çº¿ç¨‹ï¼ˆEVENTï¼Œå¼‚æ­¥é˜Ÿåˆ— + é‡è¿ï¼‰=====
class UartEventSender(threading.Thread):
    """
    å¼‚æ­¥å‘é€ EVENTï¼šä¸»çº¿ç¨‹è°ƒç”¨ send_low_density_segment() ä»…å…¥é˜Ÿï¼›åå°çº¿ç¨‹ä¸²å£å‘é€ã€‚
    """
    def __init__(self, port, baud, queue_max=EVENT_QUEUE_MAX, retry_sec=UART_RETRY_SEC):
        super().__init__(daemon=True)
        self.port = port
        self.baud = baud
        self.q = queue.Queue(maxsize=queue_max)
        self.stop_flag = threading.Event()
        self.ser = None
        self.ready = False
        self.retry_sec = retry_sec

    def open_serial(self):
        if not SERIAL_AVAILABLE:
            print("âš ï¸  pyserial ä¸å¯ç”¨ï¼šæ— æ³•ä¸‹å‘ EVENTã€‚")
            return False
        try:
            self.ser = serial.Serial(self.port, self.baud, timeout=0.2)
            print(f"âœ… UART å·²æ‰“å¼€(EVENT TX): {self.port} @ {self.baud}")
            return True
        except Exception as e:
            print(f"âš ï¸  EVENT UART æ‰“å¼€å¤±è´¥: {e}")
            return False

    def run(self):
        while not self.stop_flag.is_set():
            if not self.ready:
                self.ready = self.open_serial()
                if not self.ready:
                    time.sleep(self.retry_sec)
                    continue

            try:
                payload = self.q.get(timeout=0.2)
            except queue.Empty:
                continue

            try:
                self._send_frame(payload)
            except Exception as e:
                print(f"âš ï¸ EVENT å‘é€å¤±è´¥: {e}ï¼Œå°†é‡è¿")
                try:
                    if self.ser:
                        self.ser.close()
                except Exception:
                    pass
                self.ser = None
                self.ready = False
                time.sleep(self.retry_sec)
            finally:
                self.q.task_done()

    def stop(self):
        self.stop_flag.set()
        try:
            if self.ser:
                self.ser.close()
        except Exception:
            pass

    def _send_frame(self, payload: bytes):
        header = b'\xAA\x55' + bytes([EVENT_MSG_TYPE]) + bytes([len(payload)])
        frame_wo_crc = header + payload
        crc = crc16_ccitt_false(frame_wo_crc)
        frame = frame_wo_crc + struct.pack('<H', crc)
        if self.ser:
            self.ser.write(frame)

    def send_low_density_segment(self, event_id: int, severity: int,
                                 s_start_mm: int, s_end_mm: int,
                                 seed_count: int, weight_mg: int):
        payload = struct.pack(
            '<HBBIIHI',
            int(event_id) & 0xFFFF,
            EVENT_TYPE_LOW_DENSITY_SEG,
            int(severity) & 0xFF,
            int(s_start_mm) & 0xFFFFFFFF,
            int(s_end_mm) & 0xFFFFFFFF,
            int(seed_count) & 0xFFFF,
            int(weight_mg) & 0xFFFFFFFF
        )
        try:
            self.q.put(payload, timeout=0.01)
        except queue.Full:
            print("âš ï¸ EVENT é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒä¸€æ¡ä½å¯†åº¦äº‹ä»¶ã€‚")


# ===== ç›¸æœº =====
class MVS_Camera:
    def __init__(self):
        self.camera = None
        self.is_opened = False

    def open_camera(self):
        try:
            MvCamera.MV_CC_Initialize()

            device_list = MV_CC_DEVICE_INFO_LIST()
            tlayerType = MV_GIGE_DEVICE | MV_USB_DEVICE
            ret = MvCamera.MV_CC_EnumDevices(tlayerType, device_list)
            print(f"æšä¸¾è®¾å¤‡: ret=0x{ret:08X}, æ•°é‡={device_list.nDeviceNum}")
            if ret != 0 or device_list.nDeviceNum == 0:
                return False

            self.camera = MvCamera()
            st_device = cast(device_list.pDeviceInfo[0], POINTER(MV_CC_DEVICE_INFO)).contents

            ret = self.camera.MV_CC_CreateHandle(st_device)
            if ret != 0:
                return False

            ret = self.camera.MV_CC_OpenDevice(MV_ACCESS_Exclusive, 0)
            if ret != 0:
                return False

            ret = self.camera.MV_CC_SetEnumValue("TriggerMode", MV_TRIGGER_MODE_OFF)
            if ret != 0:
                print(f"âš ï¸ TriggerModeè®¾ç½®å¤±è´¥: 0x{ret:08X}")

            # é™ä½ç¼“å­˜å‡å°‘ç§¯å‹
            self.camera.MV_CC_SetImageNodeNum(6)

            ret = self.camera.MV_CC_StartGrabbing()
            if ret != 0:
                self.camera.MV_CC_CloseDevice()
                return False

            self.is_opened = True
            return True
        except Exception:
            return False

    def capture_frame_alternative(self):
        if not self.is_opened:
            return None

        stFrame = MV_FRAME_OUT()
        memset(byref(stFrame), 0, sizeof(stFrame))

        ret = self.camera.MV_CC_GetImageBuffer(stFrame, 5000)
        if ret != 0:
            return None

        buffer_size = stFrame.stFrameInfo.nFrameLen
        # Optimize: Use np.frombuffer directly without memmove
        # This avoids an extra memory copy operation
        image_array = np.frombuffer(
            (c_ubyte * buffer_size).from_address(stFrame.pBufAddr), 
            dtype=np.ubyte, 
            count=buffer_size
        ).copy()  # Still need a copy since we must free the buffer

        frame = None
        pixel_type = stFrame.stFrameInfo.enPixelType

        try:
            if pixel_type == PixelType_Gvsp_BGR8_Packed:
                frame = image_array.reshape((stFrame.stFrameInfo.nHeight, stFrame.stFrameInfo.nWidth, 3))
            elif pixel_type == PixelType_Gvsp_RGB8_Packed:
                frame = image_array.reshape((stFrame.stFrameInfo.nHeight, stFrame.stFrameInfo.nWidth, 3))
                frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
            elif pixel_type == PixelType_Gvsp_Mono8:
                frame = image_array.reshape((stFrame.stFrameInfo.nHeight, stFrame.stFrameInfo.nWidth))
                frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)
            elif pixel_type == PixelType_Gvsp_BayerRG8:
                frame = image_array.reshape((stFrame.stFrameInfo.nHeight, stFrame.stFrameInfo.nWidth))
                frame = cv2.cvtColor(frame, cv2.COLOR_BayerRG2BGR)
            elif pixel_type == PixelType_Gvsp_BayerGB8:
                frame = image_array.reshape((stFrame.stFrameInfo.nHeight, stFrame.stFrameInfo.nWidth))
                frame = cv2.cvtColor(frame, cv2.COLOR_BayerGB2BGR)
            elif pixel_type == PixelType_Gvsp_BayerGR8:
                frame = image_array.reshape((stFrame.stFrameInfo.nHeight, stFrame.stFrameInfo.nWidth))
                frame = cv2.cvtColor(frame, cv2.COLOR_BayerGR2BGR)
            elif pixel_type == PixelType_Gvsp_BayerBG8:
                frame = image_array.reshape((stFrame.stFrameInfo.nHeight, stFrame.stFrameInfo.nWidth))
                frame = cv2.cvtColor(frame, cv2.COLOR_BayerBG2BGR)
        except Exception:
            frame = None

        self.camera.MV_CC_FreeImageBuffer(stFrame)
        return frame

    def close(self):
        if self.camera:
            try:
                if self.is_opened:
                    self.camera.MV_CC_StopGrabbing()
                    self.camera.MV_CC_CloseDevice()
                self.camera.MV_CC_DestroyHandle()
            except Exception:
                pass
            self.is_opened = False

        try:
            MvCamera.MV_CC_Finalize()
        except Exception:
            pass


# ===== å¢å¼ºè¿½è¸ªå™¨ï¼ˆIOU + å¹³æ»‘ + ä¸¢å¤±å®¹å¿ + åŒºåŸŸ/æ–¹å‘çº¦æŸï¼‰=====
class EnhancedTracker:
    def __init__(self,
                 iou_thresh=0.3,
                 max_frames_missing=15,
                 smoothing=0.5,
                 count_zone=None):
        """
        count_zone: (x1,y1,x2,y2) è®¡æ•°åŒºåŸŸï¼ŒNone è¡¨ç¤ºå…¨å¸§
        """
        self.tracks = {}
        self.next_id = 0
        self.iou_thresh = iou_thresh
        self.max_frames_missing = max_frames_missing
        self.smoothing = smoothing
        self.frame_count = 0
        self.count_zone = count_zone

    def _bbox_center(self, bbox):
        x1, y1, x2, y2 = bbox
        return ((x1 + x2) / 2.0, (y1 + y2) / 2.0)

    def _iou(self, b1, b2):
        x11, y11, x12, y12 = b1
        x21, y21, x22, y22 = b2
        xi1, yi1 = max(x11, x21), max(y11, y21)
        xi2, yi2 = min(x12, x22), min(y12, y22)
        if xi2 <= xi1 or yi2 <= yi1:
            return 0.0
        inter = (xi2 - xi1) * (yi2 - yi1)
        area1 = (x12 - x11) * (y12 - y11)
        area2 = (x22 - x21) * (y22 - y21)
        union = area1 + area2 - inter
        if union <= 0:
            return 0.0
        return inter / union

    def _in_count_zone(self, center):
        if self.count_zone is None:
            return True
        x1, y1, x2, y2 = self.count_zone
        return (x1 <= center[0] <= x2) and (y1 <= center[1] <= y2)

    def update(self, detections):
        self.frame_count += 1

        # 1) é¢„æµ‹é˜¶æ®µï¼šä»…ä¿ç•™æœªè¶…æœŸ track
        active_tracks = {}
        for tid, t in self.tracks.items():
            if self.frame_count - t['last_seen'] <= self.max_frames_missing:
                active_tracks[tid] = t
        self.tracks = active_tracks

        if not detections:
            return []

        # 2) IOU åŒ¹é…
        unmatched_dets = set(range(len(detections)))
        for tid, t in list(self.tracks.items()):
            best_det = None
            best_iou = 0.0
            for i in unmatched_dets:
                iou_val = self._iou(t['bbox'], detections[i]['bbox'])
                if iou_val > best_iou:
                    best_iou = iou_val
                    best_det = i
            if best_iou >= self.iou_thresh and best_det is not None:
                det = detections[best_det]
                # å¹³æ»‘ bbox
                new_bbox = [
                    int(self.smoothing * det['bbox'][0] + (1 - self.smoothing) * t['bbox'][0]),
                    int(self.smoothing * det['bbox'][1] + (1 - self.smoothing) * t['bbox'][1]),
                    int(self.smoothing * det['bbox'][2] + (1 - self.smoothing) * t['bbox'][2]),
                    int(self.smoothing * det['bbox'][3] + (1 - self.smoothing) * t['bbox'][3]),
                ]
                new_center = self._bbox_center(new_bbox)
                t['bbox'] = new_bbox
                t['center'] = new_center
                t['last_seen'] = self.frame_count
                t['history'].append(new_center)
                if len(t['history']) > 30:
                    t['history'] = t['history'][-30:]
                # æ›´æ–°æ–¹å‘
                if len(t['history']) >= 2:
                    prev_y = t['history'][-2][1]
                    curr_y = t['history'][-1][1]
                    t['direction'] = 'up' if curr_y < prev_y else 'down'
                unmatched_dets.remove(best_det)

        # 3) æ–°å»º track
        for i in list(unmatched_dets):
            det = detections[i]
            center = self._bbox_center(det['bbox'])
            self.tracks[self.next_id] = {
                'bbox': det['bbox'],
                'center': center,
                'last_seen': self.frame_count,
                'history': [center],
                'direction': 'unknown',
                'counted': False
            }
            self.next_id += 1

        # 4) è¾“å‡º
        updated_tracks = []
        for tid, t in self.tracks.items():
            updated_tracks.append({
                'track_id': tid,
                'bbox': t['bbox'],
                'center': t['center'],
                'history': t['history'],
                'direction': t.get('direction', 'unknown'),
                'counted': t.get('counted', False),
            })
        return updated_tracks


def check_crossing_strict_direction(tracked_objects, count_line_y, counted_objects, counting_direction, count_zone=None):
    new_counts = 0
    for obj in tracked_objects:
        track_id = obj['track_id']
        if track_id in counted_objects:
            continue
        history = obj.get('history', [])
        if len(history) < 2:
            continue
        prev_y = history[-2][1]
        curr_y = history[-1][1]
        obj_direction = obj.get('direction', 'unknown')
        center_now = history[-1]

        # åŒºåŸŸçº¦æŸ
        if count_zone:
            x1, y1, x2, y2 = count_zone
            if not (x1 <= center_now[0] <= x2 and y1 <= center_now[1] <= y2):
                continue

        if counting_direction == "up":
            if prev_y > count_line_y and curr_y <= count_line_y and obj_direction == 'up':
                counted_objects.add(track_id)
                obj['counted'] = True
                new_counts += 1
        elif counting_direction == "down":
            if prev_y < count_line_y and curr_y >= count_line_y and obj_direction == 'down':
                counted_objects.add(track_id)
                obj['counted'] = True
                new_counts += 1
    return new_counts, counted_objects


# ====== YOLO æ¨ç†ï¼šengine / onnx / pt å…¼å®¹ ======
class BaseDetector:
    def infer(self, frame_bgr, roi=None, downsample_ratio=1.0):
        raise NotImplementedError


class TRTDetector(BaseDetector):
    def __init__(self, engine_path, input_size=640, conf_thres=0.15, iou_thres=0.10, max_det=MAX_DETECTIONS):
        if not TRT_AVAILABLE:
            raise RuntimeError("TensorRT/pycuda ä¸å¯ç”¨ï¼Œæ— æ³•åŠ è½½ .engine")
        self.engine_path = engine_path
        self.input_size = input_size
        self.conf_thres = conf_thres
        self.iou_thres = iou_thres
        self.max_det = max_det

        self.logger = trt.Logger(trt.Logger.ERROR)
        with open(engine_path, 'rb') as f, trt.Runtime(self.logger) as runtime:
            self.engine = runtime.deserialize_cuda_engine(f.read())
        self.context = self.engine.create_execution_context()

        self.inputs = []
        self.outputs = []
        self.bindings = []
        self.stream = cuda.Stream()
        self.input_binding = None

        for binding in self.engine:
            size = trt.volume(self.engine.get_tensor_shape(binding))
            dtype = trt.nptype(self.engine.get_tensor_dtype(binding))
            host_mem = cuda.pagelocked_empty(size, dtype)
            device_mem = cuda.mem_alloc(host_mem.nbytes)
            self.bindings.append(int(device_mem))
            if self.engine.get_tensor_mode(binding) == trt.TensorIOMode.INPUT:
                self.inputs.append((binding, host_mem, device_mem))
                if self.input_binding is None:
                    self.input_binding = binding
            else:
                self.outputs.append((binding, host_mem, device_mem))

    def _ensure_input_shape(self, inp_shape):
        """ä¸ºåŠ¨æ€shapeçš„engineè®¾ç½®å®é™…è¾“å…¥å½¢çŠ¶ï¼Œé¿å…æ‰§è¡Œæ—¶å½¢çŠ¶ç¼ºå¤±å¯¼è‡´çš„CaskæŠ¥é”™ã€‚"""
        if self.input_binding is None:
            return
        try:
            # TensorRT 10.x
            if hasattr(self.context, "set_input_shape"):
                self.context.set_input_shape(self.input_binding, inp_shape)
                return
            # TensorRT 8.x
            if hasattr(self.context, "set_binding_shape"):
                if hasattr(self.engine, "get_tensor_index"):
                    idx = self.engine.get_tensor_index(self.input_binding)
                else:
                    idx = self.engine.get_binding_index(self.input_binding)
                self.context.set_binding_shape(idx, inp_shape)
        except Exception as e:
            raise RuntimeError(f"è®¾ç½®TensorRTè¾“å…¥å½¢çŠ¶å¤±è´¥: {e}")

    def _preprocess(self, img_bgr):
        """ä¼˜åŒ–çš„é¢„å¤„ç†ï¼šåˆå¹¶è‰²å½©ç©ºé—´è½¬æ¢å’Œresizeï¼Œå‡å°‘å†…å­˜æ‹·è´"""
        # ä½¿ç”¨cv2.resizeçš„æ’å€¼å‚æ•°æ¥åŠ é€Ÿï¼ˆINTER_LINEARæ¯”INTER_CUBICå¿«ï¼Œä½†è´¨é‡è¶³å¤Ÿï¼‰
        # å…ˆresizeå†è½¬æ¢è‰²å½©ç©ºé—´ï¼Œå¯ä»¥å‡å°‘å¤„ç†çš„åƒç´ æ•°é‡
        img = cv2.resize(img_bgr, (self.input_size, self.input_size), interpolation=cv2.INTER_LINEAR)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        # åˆå¹¶å½’ä¸€åŒ–å’Œè½¬ç½®æ“ä½œ
        img = img.astype(np.float32) / 255.0
        img = np.transpose(img, (2, 0, 1))[None, ...]
        return np.ascontiguousarray(img)

    def infer(self, frame_bgr, roi=None, downsample_ratio=1.0):
        # å¦‚æœæ²¡æœ‰ROIï¼Œåˆ™å…¨å±è¯†åˆ«
        if roi is None:
            img = frame_bgr
            roi_top, roi_left = 0, 0
            # ä¸å¯ç”¨è®¡æ•°æ—¶ï¼Œä½¿ç”¨å…¨å±ï¼Œä½†ä¸ºäº†ç»Ÿä¸€ï¼Œæˆ‘ä»¬è®¾ç½®roiä¸ºå…¨å±
            roi_width, roi_height = img.shape[1], img.shape[0]
        else:
            x, y, w, h = roi
            img = frame_bgr[y:y + h, x:x + w]
            roi_top, roi_left = y, x
            roi_width, roi_height = w, h
        
        # åº”ç”¨ä¸‹é‡‡æ · - ä¼˜åŒ–ï¼šä½¿ç”¨INTER_LINEARä»¥æå‡é€Ÿåº¦
        if downsample_ratio != 1.0 and downsample_ratio > 0:
            orig_h, orig_w = img.shape[:2]
            new_w = int(orig_w * downsample_ratio)
            new_h = int(orig_h * downsample_ratio)
            img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
            scale_factor = 1.0 / downsample_ratio
        else:
            scale_factor = 1.0
            
        if img is None or img.size == 0:
            return []

        inp = self._preprocess(img)
        # å¯¹åŠ¨æ€shapeçš„engineæ˜¾å¼è®¾ç½®è¾“å…¥å½¢çŠ¶ï¼Œé¿å…æ‰§è¡Œé˜¶æ®µæŠ›å‡ºCask convolutioné”™è¯¯
        self._ensure_input_shape(inp.shape)
        _, in_host, in_dev = self.inputs[0]
        np.copyto(in_host, inp.ravel())
        cuda.memcpy_htod_async(in_dev, in_host, self.stream)
        
        # TensorRTç‰ˆæœ¬è‡ªé€‚åº”æ‰§è¡Œ
        try:
            # å…ˆå°è¯•TensorRT 8.xçš„API
            self.context.execute_async_v2(bindings=self.bindings, stream_handle=self.stream.handle)
        except AttributeError:
            try:
                # å°è¯•TensorRT 10.xçš„execute_v2ï¼ˆåŒæ­¥ï¼‰
                self.context.execute_v2(bindings=self.bindings)
                # åŒæ­¥æ‰§è¡Œåéœ€è¦åŒæ­¥æµ
                self.stream.synchronize()
            except AttributeError:
                try:
                    # å°è¯•TensorRT 10.xçš„enqueue_v3ï¼ˆå¼‚æ­¥ï¼‰
                    self.context.enqueue_v3(self.stream)
                except AttributeError:
                    # æœ€åå°è¯•æ—§ç‰ˆæœ¬API
                    self.context.execute_async(bindings=self.bindings, stream_handle=self.stream.handle)
        
        # æ— è®ºå“ªç§æ–¹å¼æ‰§è¡Œï¼Œéƒ½éœ€è¦åŒæ­¥æµä»¥ç¡®ä¿è¾“å‡ºæ•°æ®å°±ç»ª
        for _, out_host, out_dev in self.outputs:
            cuda.memcpy_dtoh_async(out_host, out_dev, self.stream)
        self.stream.synchronize()

        out = np.array(self.outputs[0][1])

        dets = []
        # å¤„ç†YOLO26å¯èƒ½çš„å¤šç§è¾“å‡ºæ ¼å¼
        # æ ¼å¼1: (N, 6) [x1, y1, x2, y2, conf, cls] - ä¼ ç»Ÿæ ¼å¼
        # æ ¼å¼2: (N, 5+num_classes) [x1, y1, x2, y2, conf, cls0, cls1, ...] - YOLO26å¯èƒ½æ ¼å¼
        
        # é¦–å…ˆå°è¯•ä¼ ç»Ÿæ ¼å¼
        if out.size % 6 == 0:
            out = out.reshape(-1, 6)
            out = out[:self.max_det]  # é™åˆ¶æ£€æµ‹æ•°é‡
            for row in out:
                x1, y1, x2, y2, conf, cls = row
                conf = float(conf)
                if conf < self.conf_thres:
                    continue
                # ç¼©æ”¾å›åŸå§‹ROIå°ºå¯¸
                x1 = int(x1 * (img.shape[1] / self.input_size) * scale_factor) + roi_left
                x2 = int(x2 * (img.shape[1] / self.input_size) * scale_factor) + roi_left
                y1 = int(y1 * (img.shape[0] / self.input_size) * scale_factor) + roi_top
                y2 = int(y2 * (img.shape[0] / self.input_size) * scale_factor) + roi_top
                dets.append({'bbox': [x1, y1, x2, y2], 'confidence': conf, 'class': int(cls), 'label': f'class_{int(cls)}'})
        # å°è¯•YOLO26æ ¼å¼ (5+num_classes)
        elif out.size > 0 and out.size % out.shape[-1] == 0:
            num_cols = out.shape[-1]
            if num_cols >= 6:  # è‡³å°‘æœ‰5ä¸ªæ¡†åæ ‡+1ä¸ªç½®ä¿¡åº¦
                out = out[:self.max_det]  # é™åˆ¶æ£€æµ‹æ•°é‡
                for row in out.reshape(-1, num_cols):
                    x1, y1, x2, y2, obj_conf = row[0:5]
                    # è·å–ç±»åˆ«åˆ†æ•°
                    cls_scores = row[5:]
                    cls_id = np.argmax(cls_scores)
                    cls_conf = float(cls_scores[cls_id])
                    # ç»¼åˆç½®ä¿¡åº¦ = å¯¹è±¡ç½®ä¿¡åº¦ * ç±»åˆ«ç½®ä¿¡åº¦
                    final_conf = float(obj_conf) * cls_conf
                    if final_conf < self.conf_thres:
                        continue
                    # ç¼©æ”¾å›åŸå§‹ROIå°ºå¯¸
                    x1 = int(x1 * (img.shape[1] / self.input_size) * scale_factor) + roi_left
                    x2 = int(x2 * (img.shape[1] / self.input_size) * scale_factor) + roi_left
                    y1 = int(y1 * (img.shape[0] / self.input_size) * scale_factor) + roi_top
                    y2 = int(y2 * (img.shape[0] / self.input_size) * scale_factor) + roi_top
                    dets.append({'bbox': [x1, y1, x2, y2], 'confidence': final_conf, 'class': int(cls_id), 'label': f'class_{int(cls_id)}'})
        
        # å¯é€‰çš„NMSå¤„ç†ï¼ˆå¯¹äºç«¯åˆ°ç«¯æ¨¡å‹å¯ä»¥å…³é—­ï¼‰
        if USE_NMS_FOR_YOLO26 and len(dets) > 0:
            dets = self._apply_nms(dets)
            
        return dets
    
    def _apply_nms(self, detections):
        """åº”ç”¨éæå¤§å€¼æŠ‘åˆ¶"""
        if not detections:
            return []
        
        boxes = np.array([d['bbox'] for d in detections])
        scores = np.array([d['confidence'] for d in detections])
        
        # ä½¿ç”¨OpenCVçš„NMS
        indices = cv2.dnn.NMSBoxes(
            boxes.tolist(), scores.tolist(), 
            self.conf_thres, self.iou_thres
        )
        
        if len(indices) > 0:
            indices = indices.flatten()
            return [detections[i] for i in indices]
        return []


class OnnxDetector(BaseDetector):
    def __init__(self, onnx_path, input_size=640, conf_thres=0.15, iou_thres=0.10, max_det=MAX_DETECTIONS):
        import onnxruntime as ort
        # åˆ›å»ºä¼šè¯é€‰é¡¹ï¼Œè®¾ç½®æ—¥å¿—çº§åˆ«å‡å°‘è¾“å‡º
        so = ort.SessionOptions()
        so.log_severity_level = 3  # 3=ERROR, 2=WARNING, 1=INFO, 0=VERBOSE
        
        self.session = ort.InferenceSession(onnx_path, sess_options=so, 
                                           providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])
        self.input_name = self.session.get_inputs()[0].name
        self.input_size = input_size
        self.conf_thres = conf_thres
        self.iou_thres = iou_thres
        self.max_det = max_det

    def _preprocess(self, img_bgr):
        """ä¼˜åŒ–çš„é¢„å¤„ç†ï¼šå…ˆresizeå†è½¬æ¢è‰²å½©ç©ºé—´"""
        img = cv2.resize(img_bgr, (self.input_size, self.input_size), interpolation=cv2.INTER_LINEAR)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = img.astype(np.float32) / 255.0
        img = np.transpose(img, (2, 0, 1))[None, ...]
        return np.ascontiguousarray(img)

    def infer(self, frame_bgr, roi=None, downsample_ratio=1.0):
        # å¦‚æœæ²¡æœ‰ROIï¼Œåˆ™å…¨å±è¯†åˆ«
        if roi is None:
            img = frame_bgr
            roi_top, roi_left = 0, 0
        else:
            x, y, w, h = roi
            img = frame_bgr[y:y + h, x:x + w]
            roi_top, roi_left = y, x
        
        # åº”ç”¨ä¸‹é‡‡æ · - ä¼˜åŒ–ï¼šä½¿ç”¨INTER_LINEARä»¥æå‡é€Ÿåº¦
        if downsample_ratio != 1.0 and downsample_ratio > 0:
            orig_h, orig_w = img.shape[:2]
            new_w = int(orig_w * downsample_ratio)
            new_h = int(orig_h * downsample_ratio)
            img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
            scale_factor = 1.0 / downsample_ratio
        else:
            scale_factor = 1.0
            
        if img is None or img.size == 0:
            return []

        inp = self._preprocess(img)
        outputs = self.session.run(None, {self.input_name: inp})
        out = np.array(outputs[0])

        if out.ndim == 3 and out.shape[0] == 1:
            out = out[0]

        dets = []
        # å¤„ç†å¤šç§è¾“å‡ºæ ¼å¼ï¼Œæ”¯æŒYOLO26
        if out.size % 6 == 0:
            # ä¼ ç»Ÿæ ¼å¼ (N, 6)
            out = out.reshape(-1, 6)
            out = out[:self.max_det]  # é™åˆ¶æ£€æµ‹æ•°é‡
            for x1, y1, x2, y2, conf, cls in out:
                conf = float(conf)
                if conf < self.conf_thres:
                    continue
                # ç¼©æ”¾å›åŸå§‹ROIå°ºå¯¸
                x1 = int(x1 * (img.shape[1] / self.input_size) * scale_factor) + roi_left
                x2 = int(x2 * (img.shape[1] / self.input_size) * scale_factor) + roi_left
                y1 = int(y1 * (img.shape[0] / self.input_size) * scale_factor) + roi_top
                y2 = int(y2 * (img.shape[0] / self.input_size) * scale_factor) + roi_top
                dets.append({'bbox': [x1, y1, x2, y2], 'confidence': conf, 'class': int(cls), 'label': f'class_{int(cls)}'})
        elif out.size > 0:
            # å°è¯•å¤„ç†YOLO26æ ¼å¼ (N, 5+num_classes)
            try:
                num_cols = out.shape[-1]
                if num_cols >= 6:
                    out = out[:self.max_det]  # é™åˆ¶æ£€æµ‹æ•°é‡
                    for row in out.reshape(-1, num_cols):
                        x1, y1, x2, y2, obj_conf = row[0:5]
                        cls_scores = row[5:]
                        cls_id = np.argmax(cls_scores)
                        cls_conf = float(cls_scores[cls_id])
                        final_conf = float(obj_conf) * cls_conf
                        if final_conf < self.conf_thres:
                            continue
                        # ç¼©æ”¾å›åŸå§‹ROIå°ºå¯¸
                        x1 = int(x1 * (img.shape[1] / self.input_size) * scale_factor) + roi_left
                        x2 = int(x2 * (img.shape[1] / self.input_size) * scale_factor) + roi_left
                        y1 = int(y1 * (img.shape[0] / self.input_size) * scale_factor) + roi_top
                        y2 = int(y2 * (img.shape[0] / self.input_size) * scale_factor) + roi_top
                        dets.append({'bbox': [x1, y1, x2, y2], 'confidence': final_conf, 'class': int(cls_id), 'label': f'class_{int(cls_id)}'})
            except Exception as e:
                print(f"âš ï¸ è§£æYOLO26è¾“å‡ºæ—¶å‡ºé”™: {e}")
        
        # å¯é€‰çš„NMSå¤„ç†
        if USE_NMS_FOR_YOLO26 and len(dets) > 0:
            dets = self._apply_nms(dets)
            
        return dets
    
    def _apply_nms(self, detections):
        """åº”ç”¨éæå¤§å€¼æŠ‘åˆ¶"""
        if not detections:
            return []
        
        boxes = np.array([d['bbox'] for d in detections])
        scores = np.array([d['confidence'] for d in detections])
        
        indices = cv2.dnn.NMSBoxes(
            boxes.tolist(), scores.tolist(), 
            self.conf_thres, self.iou_thres
        )
        
        if len(indices) > 0:
            indices = indices.flatten()
            return [detections[i] for i in indices]
        return []


class PtDetector(BaseDetector):
    def __init__(self, pt_path, input_size=640, conf_thres=0.15, iou_thres=0.10, max_det=MAX_DETECTIONS, use_cpu=False):
        if not TORCH_AVAILABLE or not YOLOV5_CODE_AVAILABLE:
            raise RuntimeError("Torch æˆ– yolov5 ä»£ç ä¸å¯ç”¨ï¼Œæ— æ³•åŠ è½½ .pt")
        self.input_size = input_size
        self.conf_thres = conf_thres
        self.iou_thres = iou_thres
        self.max_det = max_det
        device = torch.device('cpu') if use_cpu else torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = DetectMultiBackend(pt_path, device=device)
        self.names = self.model.names

    def infer(self, frame_bgr, roi=None, downsample_ratio=1.0):
        # å¦‚æœæ²¡æœ‰ROIï¼Œåˆ™å…¨å±è¯†åˆ«
        if roi is None:
            img0 = frame_bgr
            roi_top, roi_left = 0, 0
        else:
            x, y, w, h = roi
            img0 = frame_bgr[y:y + h, x:x + w]
            roi_top, roi_left = y, x
            
        # åº”ç”¨ä¸‹é‡‡æ · - ä¼˜åŒ–ï¼šä½¿ç”¨INTER_LINEARä»¥æå‡é€Ÿåº¦
        if downsample_ratio != 1.0 and downsample_ratio > 0:
            orig_h, orig_w = img0.shape[:2]
            new_w = int(orig_w * downsample_ratio)
            new_h = int(orig_h * downsample_ratio)
            img0 = cv2.resize(img0, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
            scale_factor = 1.0 / downsample_ratio
        else:
            scale_factor = 1.0
            
        if img0 is None or img0.size == 0:
            return []

        img_lb = letterbox(img0, self.input_size, stride=self.model.stride, auto=True)[0]
        img_chw = img_lb.transpose((2, 0, 1))[::-1]
        img_chw = np.ascontiguousarray(img_chw)

        im = torch.from_numpy(img_chw).to(self.model.device)
        im = im.float() / 255.0
        if len(im.shape) == 3:
            im = im[None]

        with torch.no_grad():
            pred = self.model(im, augment=False, visualize=False)
            pred = non_max_suppression(pred, self.conf_thres, self.iou_thres, None, False, max_det=self.max_det)

        dets = []
        for det in pred:
            if len(det):
                det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], img0.shape).round()
                for *xyxy, conf, cls in det:
                    x1, y1, x2, y2 = map(int, xyxy)
                    conf = float(conf)
                    cls = int(cls)
                    # ç¼©æ”¾å›åŸå§‹ROIå°ºå¯¸
                    x1 = int(x1 * scale_factor) + roi_left
                    x2 = int(x2 * scale_factor) + roi_left
                    y1 = int(y1 * scale_factor) + roi_top
                    y2 = int(y2 * scale_factor) + roi_top
                    dets.append({
                        'bbox': [x1, y1, x2, y2],
                        'confidence': conf,
                        'class': cls,
                        'label': self.names[cls] if self.names else f'class_{cls}'
                    })
        return dets


def choose_model_file(default_path=DEFAULT_MODEL_PATH):
    if default_path and os.path.isfile(default_path):
        return default_path
    for p in MODEL_CANDIDATES:
        if os.path.isfile(p):
            return p
    return None


def create_detector(model_path):
    if model_path is None:
        raise RuntimeError("æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ï¼Œè¯·æ”¾ç½® yolov12sbest.engine æˆ–å…¶ä»–å€™é€‰æ–‡ä»¶")
    ext = os.path.splitext(model_path)[1].lower()
    if ext == ".engine":
        print(f"ğŸ”§ ä½¿ç”¨ TensorRT Engine: {model_path}")
        return TRTDetector(model_path)
    if ext == ".onnx":
        print(f"ğŸ”§ ä½¿ç”¨ ONNXRuntime: {model_path}")
        return OnnxDetector(model_path)
    if ext == ".pt":
        print(f"ğŸ”§ ä½¿ç”¨ PyTorch(.pt): {model_path}")
        return PtDetector(model_path)
    raise RuntimeError(f"ä¸æ”¯æŒçš„æ¨¡å‹åç¼€: {ext}")


# ===== å¯†åº¦è¯†åˆ« =====
class DensityDetector:
    def __init__(self, cols=16, rows=6, low_ratio=0.35):
        self.cols = cols
        self.rows = rows
        self.low_ratio = low_ratio
        self.in_low = False
        self.low_cnt = 0
        self.recover_cnt = 0
        self.current_start_s = None
        self.current_seed_sum = 0  # ä½å¯†åº¦åŒºé—´å†…çš„ç§å­ç´¯è®¡ï¼ˆç”¨äºé‡é‡æ¢ç®—ï¼‰
        self.current_frames = 0

    def compute_density_map(self, detections, roi_rect):
        x, y, w, h = roi_rect
        dm = np.zeros((self.rows, self.cols), dtype=np.float32)
        if w <= 1 or h <= 1:
            return dm

        for det in detections:
            x1, y1, x2, y2 = det['bbox']
            cx = (x1 + x2) * 0.5
            cy = (y1 + y2) * 0.5
            if cx < x or cx >= x + w or cy < y or cy >= y + h:
                continue
            gx = int((cx - x) / w * self.cols)
            gy = int((cy - y) / h * self.rows)
            gx = max(0, min(self.cols - 1, gx))
            gy = max(0, min(self.rows - 1, gy))
            dm[gy, gx] += 1.0
        return dm

    def low_density_columns(self, density_map):
        col_sum = density_map.sum(axis=0)
        mean = float(col_sum.mean()) if col_sum.size else 0.0
        if mean <= 1e-6:
            return [], col_sum, mean, 0.0
        thr = mean * self.low_ratio
        low = col_sum < thr

        segs = []
        start = None
        for i, is_low in enumerate(low):
            if is_low and start is None:
                start = i
            elif (not is_low) and start is not None:
                segs.append((start, i - 1))
                start = None
        if start is not None:
            segs.append((start, self.cols - 1))
        return segs, col_sum, mean, thr

    def update_segment_state(self, has_significant_low: bool, s_cap: int, seed_count_frame: int):
        """
        è¿”å›ä¸€ä¸ªå®Œæ•´åŒºé—´ï¼š
          (s_start, s_end, seed_count_in_segment)
        """
        if has_significant_low:
            self.low_cnt += 1
            self.recover_cnt = 0
            if (not self.in_low) and self.low_cnt >= LOW_DENSITY_MIN_FRAMES:
                self.in_low = True
                self.current_start_s = s_cap
                self.current_seed_sum = 0
                self.current_frames = 0

            if self.in_low:
                self.current_seed_sum += int(seed_count_frame)
                self.current_frames += 1
            return None

        # not low
        self.low_cnt = 0
        if self.in_low:
            self.recover_cnt += 1
            if self.recover_cnt >= RECOVER_MIN_FRAMES:
                self.in_low = False
                self.recover_cnt = 0
                s_start = self.current_start_s
                s_end = s_cap
                seed_sum = self.current_seed_sum
                self.current_start_s = None
                self.current_seed_sum = 0
                self.current_frames = 0
                if s_start is not None and s_end is not None and s_end >= s_start:
                    return (int(s_start), int(s_end), int(seed_sum))
        return None

    def draw_density_map(self, frame, density_map, roi_rect):
        x, y, w, h = roi_rect
        dm = density_map
        dm_norm = dm.copy()
        if dm_norm.max() > 0:
            dm_norm = dm_norm / dm_norm.max()
        dm_img = (dm_norm * 255).astype(np.uint8)
        dm_img = cv2.resize(dm_img, (w, h), interpolation=cv2.INTER_NEAREST)
        dm_color = cv2.applyColorMap(dm_img, cv2.COLORMAP_JET)
        overlay = frame.copy()
        overlay[y:y + h, x:x + w] = cv2.addWeighted(frame[y:y + h, x:x + w], 0.5, dm_color, 0.5, 0)
        return overlay


# ===== ä½å¯†åº¦åŒºé—´ç¼“å­˜ï¼ˆå¼‚æ­¥å†™ç›˜ + è½®è½¬ï¼‰=====
class SegmentCache(threading.Thread):
    def __init__(self, path, merge_gap_mm=80,
                 queue_max=CACHE_QUEUE_MAX,
                 flush_interval=CACHE_FLUSH_INTERVAL,
                 rotate_lines=CACHE_ROTATE_LINES,
                 rotate_keep=CACHE_ROTATE_KEEP):
        super().__init__(daemon=True)
        self.path = path
        self.merge_gap_mm = merge_gap_mm
        self.lock = threading.Lock()
        self._last_seg = None  # (s_start, s_end, seed_count_sum, weight_mg)
        self.q = queue.Queue(maxsize=queue_max)
        self.flush_interval = flush_interval
        self.rotate_lines = rotate_lines
        self.rotate_keep = rotate_keep
        self.stop_flag = threading.Event()
        self._pending = []
        self._line_count = 0
        if os.path.isfile(self.path):
            try:
                with open(self.path, "r", encoding="utf-8") as f:
                    self._line_count = sum(1 for _ in f)
            except Exception:
                self._line_count = 0

    def rotate_if_needed(self):
        if self.rotate_lines <= 0:
            return
        if self._line_count < self.rotate_lines:
            return
        ts = time.strftime("%Y%m%d_%H%M%S")
        new_name = f"{self.path}.{ts}"
        try:
            os.rename(self.path, new_name)
            print(f"ğŸŒ€ cache rotate -> {new_name}")
        except Exception:
            pass
        self._line_count = 0
        try:
            files = sorted([f for f in os.listdir(".") if f.startswith(os.path.basename(self.path) + ".")])
            if len(files) > self.rotate_keep:
                for f in files[:-self.rotate_keep]:
                    try:
                        os.remove(f)
                    except Exception:
                        pass
        except Exception:
            pass

    def add_segment(self, s_start, s_end, seed_count_sum: int, weight_mg: int, meta=None):
        if s_end < s_start:
            return

        with self.lock:
            seg = (int(s_start), int(s_end), int(seed_count_sum), int(weight_mg))
            if self._last_seg is None:
                self._last_seg = seg
                self._enqueue(seg, meta)
                return

            last_start, last_end, last_seed, last_wmg = self._last_seg
            if seg[0] <= last_end + self.merge_gap_mm:
                new_seg = (last_start, max(last_end, seg[1]), last_seed + seg[2], last_wmg + seg[3])
                self._last_seg = new_seg
                self._enqueue(new_seg, {**(meta or {}), "merged": True})
            else:
                self._last_seg = seg
                self._enqueue(seg, meta)

    def _enqueue(self, seg, meta=None):
        s_start, s_end, seed_count_sum, weight_mg = seg
        record = {
            "ts_host": time.time(),
            "s_start_mm": s_start,
            "s_end_mm": s_end,
            "seed_count": seed_count_sum,
            "weight_g": weight_mg / 1000.0,
            "tkw_g_per_1000": SEED_TKW_GRAMS,
        }
        if meta:
            record.update(meta)
        try:
            self.q.put(record, timeout=0.01)
        except queue.Full:
            print("âš ï¸ cache é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒä¸€æ¡è®°å½•ã€‚")

    def run(self):
        last_flush = time.time()
        while not self.stop_flag.is_set():
            try:
                rec = self.q.get(timeout=0.2)
                self._pending.append(rec)
                self.q.task_done()
            except queue.Empty:
                pass

            now = time.time()
            if (now - last_flush) >= self.flush_interval or len(self._pending) >= 100:
                self.flush()
                last_flush = now

        self.flush()

    def flush(self):
        if not self._pending:
            return
        try:
            self.rotate_if_needed()
            with open(self.path, "a", encoding="utf-8") as f:
                for rec in self._pending:
                    f.write(json.dumps(rec, ensure_ascii=False) + "\n")
                    self._line_count += 1
            self._pending.clear()
        except Exception as e:
            print(f"âš ï¸ cache å†™å…¥å¤±è´¥: {e}")

    def stop(self):
        self.stop_flag.set()


# ===== UI çº¿ç¨‹ =====
class CameraThread(QThread):
    """ç›¸æœºé‡‡é›†å’Œå¤„ç†çš„çº¿ç¨‹"""
    frame_processed = pyqtSignal(np.ndarray, dict)  # å‘é€å¤„ç†åçš„å¸§å’Œç»Ÿè®¡æ•°æ®
    long_status_changed = pyqtSignal(str)          # é•¿å›¾çŠ¶æ€å˜åŒ–ï¼ˆç”¨äºUIæ˜¾ç¤ºï¼‰
    
    def __init__(self, parent=None):
        super().__init__(parent)
        self.running = False
        self.cam = None
        self.detector = None
        self.tracker = None
        self.ctrl_buf = None
        self.density_detector = None
        self.event_sender = None
        self.uart_rx = None
        self.seg_cache = None
        
        # å¯é…ç½®å‚æ•°
        self.enable_detection = True
        self.enable_tracking = True
        self.enable_density_detection = DENSITY_ENABLED_DEFAULT
        self.enable_uart_rx = True
        self.enable_uart_tx = True
        self.enable_counting = True
        
        # è®¡æ•°çº¿å‚æ•°
        self.count_line_percent = COUNT_LINE_PERCENT_DEFAULT  # è®¡æ•°çº¿ä½ç½®ç™¾åˆ†æ¯”
        self.count_line_top_extend = COUNT_LINE_TOP_EXTEND_DEFAULT  # å‘ä¸Šæ‰©å±•åƒç´ æ•°
        self.count_line_bottom_extend = COUNT_LINE_BOTTOM_EXTEND_DEFAULT  # å‘ä¸‹æ‰©å±•åƒç´ æ•°
        
        # ROIåŒºåŸŸ
        self.roi_rect = None  # å¯ç”¨è®¡æ•°æ—¶ä¸ºROIåŒºåŸŸï¼Œä¸å¯ç”¨æ—¶ä¸ºNoneï¼ˆå…¨å±è¯†åˆ«ï¼‰
        
        # ä¸‹é‡‡æ ·å‚æ•°
        self.downsample_ratio = DOWNSAMPLE_RATIO_DEFAULT
        
        # å¸§è·³è¿‡å‚æ•°ï¼ˆç”¨äºæç«¯æ€§èƒ½ä¼˜åŒ–ï¼‰
        self.frame_skip = 0  # 0=å¤„ç†æ‰€æœ‰å¸§ï¼Œ1=è·³è¿‡1å¸§å¤„ç†1å¸§ï¼Œ2=è·³è¿‡2å¸§å¤„ç†1å¸§
        self.frame_skip_counter = 0
        
        # æ€§èƒ½ç›‘æ§ï¼ˆå¯é€‰ï¼‰
        self.enable_profiling = False
        self.profile_times = {
            'capture': 0.0,
            'detection': 0.0,
            'tracking': 0.0,
            'drawing': 0.0,
            'total': 0.0,
        }
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'fps': 0,
            'detections': 0,
            'tracked': 0,
            'counted': 0,
            'low_density': False,
            'gate_state': False,
            's_mm': 0,
            'v_mmps': 0,
            'uart_rx_status': 'æœªè¿æ¥',
            'uart_tx_status': 'æœªè¿æ¥',
            'long_status': 'ç©ºé—²',
            'count_line_y': 0,
            'roi_info': 'å…¨å±',
        }
        
        # å…¶ä»–å˜é‡
        self.counted_objects = set()
        self.event_id = 1
        self.count_line_y = 0  # è®¡æ•°çº¿åƒç´ ä½ç½®
        self.counting_direction = "down"
        self.count_zone = None
        self.max_detections = MAX_DETECTIONS  # æœ€å¤§æ£€æµ‹æ•°é‡
        
        # æ€§èƒ½ç›‘æ§
        self.frame_count = 0
        self.last_fps_time = time.time()

        # é•¿å›¾æ‹¼æ¥
        self.long_capturing = False
        self.long_frames = []
        self.base_save_dir = DEFAULT_SAVE_DIR
        self.long_reason = ""
        self.manual_allowed = True  # å½“ UART å…³é—­æ—¶ç”± UI æ§åˆ¶
        self._prev_speed_positive = False
        
        # åŸå§‹å¸§å°ºå¯¸
        self.original_frame_height = 720
        self.original_frame_width = 1280
    
    def set_base_save_dir(self, path: str):
        if path:
            self.base_save_dir = path
        else:
            self.base_save_dir = DEFAULT_SAVE_DIR
    
    def update_count_line_and_roi(self, frame):
        """æ ¹æ®è®¡æ•°çº¿ç™¾åˆ†æ¯”å’Œæ‰©å±•åƒç´ æ•°æ›´æ–°è®¡æ•°çº¿ä½ç½®å’ŒROIåŒºåŸŸ"""
        if frame is None:
            return
        
        self.original_frame_height, self.original_frame_width = frame.shape[:2]
        
        # è®¡ç®—è®¡æ•°çº¿åƒç´ ä½ç½®ï¼ˆä»ä¸Šåˆ°ä¸‹ç™¾åˆ†æ¯”ï¼‰
        self.count_line_y = int(self.original_frame_height * (self.count_line_percent / 100.0))
        
        if self.enable_counting:
            # å¯ç”¨è®¡æ•°æ—¶ï¼Œè®¡ç®—ROIåŒºåŸŸ
            roi_y = max(0, self.count_line_y - self.count_line_top_extend)
            roi_h = min(self.original_frame_height - roi_y, 
                       self.count_line_top_extend + self.count_line_bottom_extend)
            roi_x = 0
            roi_w = self.original_frame_width
            
            # ç¡®ä¿ROIåŒºåŸŸæœ‰æ•ˆ
            if roi_h > 0 and roi_w > 0:
                self.roi_rect = (roi_x, roi_y, roi_w, roi_h)
                # è®¾ç½®è®¡æ•°åŒºåŸŸä¸ºROIåŒºåŸŸ
                self.count_zone = self.roi_rect
                self.stats['roi_info'] = f"{roi_w}x{roi_h}"
            else:
                self.roi_rect = None
                self.count_zone = None
                self.stats['roi_info'] = 'æ— æ•ˆ'
        else:
            # ä¸å¯ç”¨è®¡æ•°æ—¶ï¼ŒROIä¸ºNoneï¼ˆå…¨å±è¯†åˆ«ï¼‰
            self.roi_rect = None
            self.count_zone = None
            self.stats['roi_info'] = 'å…¨å±'
        
        self.stats['count_line_y'] = self.count_line_y
    
    def start_manual_long_capture(self):
        if self.enable_uart_rx and SERIAL_AVAILABLE:
            return  # UART å¼€å¯æ—¶ä¸å…è®¸æ‰‹åŠ¨
        self._start_long_capture(reason="manual")

    def stop_manual_long_capture(self):
        if self.enable_uart_rx and SERIAL_AVAILABLE:
            return  # UART å¼€å¯æ—¶ä¸å…è®¸æ‰‹åŠ¨
        self._finalize_long_capture(trigger="manual_stop")
    
    def _start_long_capture(self, reason: str):
        if self.long_capturing:
            return
        self.long_capturing = True
        self.long_reason = reason
        self.long_frames = []
        self.long_status_changed.emit(f"æ‹¼æ¥ä¸­ ({reason})")
        self.stats['long_status'] = f"æ‹¼æ¥ä¸­ ({reason})"

    def _append_long_frame(self, frame):
        if not self.long_capturing:
            return
        if len(self.long_frames) >= MAX_LONG_FRAMES:
            return
        self.long_frames.append(frame.copy())

    def _finalize_long_capture(self, trigger: str):
        if not self.long_capturing:
            return
        self.long_capturing = False
        frames = self.long_frames
        self.long_frames = []
        if not frames:
            self.long_status_changed.emit("ç©ºé—²")
            self.stats['long_status'] = "ç©ºé—²"
            return
        try:
            long_img = np.vstack(frames)
        except Exception as e:
            print(f"âš ï¸ é•¿å›¾æ‹¼æ¥å¤±è´¥: {e}")
            self.long_status_changed.emit("ç©ºé—²")
            self.stats['long_status'] = "ç©ºé—²"
            return
        if long_img.shape[0] < MIN_HEIGHT_FOR_SAVE:
            self.long_status_changed.emit("ç©ºé—²")
            self.stats['long_status'] = "ç©ºé—²"
            return

        detections = []
        annotated = long_img.copy()
        try:
            if self.detector:
                # é•¿å›¾è¯†åˆ«æ—¶ä½¿ç”¨å…¨å±è¯†åˆ«
                detections = self.detector.infer(long_img, roi=None, downsample_ratio=self.downsample_ratio)
                annotated = self._draw_simple_dets(long_img.copy(), detections)
        except Exception as e:
            print(f"âš ï¸ é•¿å›¾æ•´ä½“è¯†åˆ«å¤±è´¥: {e}")

        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        folder = os.path.join(self.base_save_dir, ts)
        os.makedirs(folder, exist_ok=True)
        long_path = os.path.join(folder, "long.jpg")
        det_path = os.path.join(folder, "long_det.jpg")
        meta_path = os.path.join(folder, "result.json")
        try:
            cv2.imwrite(long_path, long_img)
            cv2.imwrite(det_path, annotated)
            with open(meta_path, "w", encoding="utf-8") as f:
                json.dump({"trigger": trigger, "detections": detections}, f, ensure_ascii=False, indent=2)
            print(f"ğŸ“¸ é•¿å›¾å·²ä¿å­˜: {long_path}")
            print(f"âœ… è¯†åˆ«ç»“æœå·²ä¿å­˜: {det_path}")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜é•¿å›¾æˆ–ç»“æœå¤±è´¥: {e}")

        self.long_status_changed.emit("ç©ºé—²")
        self.stats['long_status'] = "ç©ºé—²"

    def _draw_simple_dets(self, img, detections):
        for det in detections:
            x1, y1, x2, y2 = det['bbox']
            conf = det.get('confidence', 0.0)
            label = det.get('label', 'obj')
            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(img, f"{label} {conf:.2f}", (x1, max(0, y1 - 5)),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
        return img
    
    def initialize(self, model_path):
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        try:
            # ç¡®ä¿ä¹‹å‰çš„ç›¸æœºèµ„æºå·²é‡Šæ”¾
            if self.cam and hasattr(self.cam, 'is_opened') and self.cam.is_opened:
                self.cam.close()
                time.sleep(0.5)  # ç­‰å¾…èµ„æºé‡Šæ”¾
            
            # åˆå§‹åŒ–ç›¸æœº
            self.cam = MVS_Camera()
            if not self.cam.open_camera():
                print("âš ï¸ ç›¸æœºæ‰“å¼€å¤±è´¥ï¼Œé‡è¯•...")
                time.sleep(1)
                if not self.cam.open_camera():
                    raise RuntimeError("ç›¸æœºæ‰“å¼€å¤±è´¥")
            print("âœ… ç›¸æœºåˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–æ£€æµ‹å™¨
            if model_path:
                self.detector = create_detector(model_path)
                print(f"âœ… æ£€æµ‹å™¨åˆå§‹åŒ–æˆåŠŸ: {model_path}")
            else:
                raise RuntimeError("æœªæŒ‡å®šæ¨¡å‹è·¯å¾„")
            
            # åˆå§‹åŒ–è¿½è¸ªå™¨
            self.tracker = EnhancedTracker(iou_thresh=0.3, max_frames_missing=15, 
                                          smoothing=0.5, count_zone=self.count_zone)
            print("âœ… è¿½è¸ªå™¨åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–æ§åˆ¶ç¼“å†²åŒº
            self.ctrl_buf = CtrlBuffer(keep_seconds=CTRL_BUFFER_SECONDS)
            print("âœ… æ§åˆ¶ç¼“å†²åŒºåˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–UARTæ¥æ”¶å™¨
            self.uart_rx = None
            if self.enable_uart_rx and SERIAL_AVAILABLE:
                try:
                    self.uart_rx = UartCtrlReceiver(UART_PORT, UART_BAUD, self.ctrl_buf)
                    self.uart_rx.start()
                    self.stats['uart_rx_status'] = 'è¿è¡Œä¸­'
                    print("âœ… UARTæ¥æ”¶å™¨å·²å¯åŠ¨")
                except Exception as e:
                    print(f"âš ï¸ UARTæ¥æ”¶å™¨å¯åŠ¨å¤±è´¥: {e}")
                    self.stats['uart_rx_status'] = 'å¯åŠ¨å¤±è´¥'
            elif self.enable_uart_rx and (not SERIAL_AVAILABLE):
                self.stats['uart_rx_status'] = 'ä¸å¯ç”¨'
            
            # åˆå§‹åŒ–UARTå‘é€å™¨
            self.event_sender = None
            if self.enable_uart_tx and SERIAL_AVAILABLE:
                try:
                    self.event_sender = UartEventSender(UART_PORT, UART_BAUD)
                    self.event_sender.start()
                    self.stats['uart_tx_status'] = 'è¿è¡Œä¸­'
                    print("âœ… UARTå‘é€å™¨å·²å¯åŠ¨")
                except Exception as e:
                    print(f"âš ï¸ UARTå‘é€å™¨å¯åŠ¨å¤±è´¥: {e}")
                    self.stats['uart_tx_status'] = 'å¯åŠ¨å¤±è´¥'
            elif self.enable_uart_tx and (not SERIAL_AVAILABLE):
                self.stats['uart_tx_status'] = 'ä¸å¯ç”¨'
            
            # åˆå§‹åŒ–å¯†åº¦æ£€æµ‹å™¨
            self.density_detector = None
            if self.enable_density_detection:
                self.density_detector = DensityDetector(cols=DENSITY_GRID_COLS, 
                                                       rows=DENSITY_GRID_ROWS, 
                                                       low_ratio=LOW_DENSITY_RATIO)
                print("âœ… å¯†åº¦æ£€æµ‹å™¨å·²åˆå§‹åŒ–")
            
            # åˆå§‹åŒ–ç¼“å­˜
            self.seg_cache = None
            try:
                self.seg_cache = SegmentCache(EVENT_CACHE_FILE, 
                                             merge_gap_mm=EVENT_MERGE_GAP_MM,
                                             queue_max=CACHE_QUEUE_MAX,
                                             flush_interval=CACHE_FLUSH_INTERVAL,
                                             rotate_lines=CACHE_ROTATE_LINES,
                                             rotate_keep=CACHE_ROTATE_KEEP)
                self.seg_cache.start()
                print("âœ… ç¼“å­˜ç³»ç»Ÿå·²å¯åŠ¨")
            except Exception as e:
                print(f"âš ï¸ ç¼“å­˜ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {e}")
            
            # é‡ç½®è®¡æ•°
            self.counted_objects.clear()
            self.event_id = 1
            
            print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            return True
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            # æ¸…ç†å·²åˆ›å»ºçš„èµ„æº
            self._cleanup_resources()
            return False
    
    def _cleanup_resources(self):
        """æ¸…ç†èµ„æº"""
        try:
            if self.cam:
                self.cam.close()
            if hasattr(self, 'uart_rx') and self.uart_rx:
                self.uart_rx.stop()
            if hasattr(self, 'event_sender') and self.event_sender:
                self.event_sender.stop()
            if self.seg_cache:
                self.seg_cache.stop()
        except Exception as e:
            print(f"æ¸…ç†èµ„æºæ—¶å‡ºé”™: {e}")
    
    def run(self):
        """çº¿ç¨‹ä¸»å¾ªç¯"""
        self.running = True
        
        while self.running:
            try:
                t_loop_start = time.perf_counter() if self.enable_profiling else 0
                
                # é‡‡é›†å¸§
                t_capture_start = time.perf_counter() if self.enable_profiling else 0
                if not self.cam:
                    time.sleep(0.01)  # Reduced from 0.1s to 10ms
                    continue
                    
                frame = self.cam.capture_frame_alternative()
                if frame is None:
                    time.sleep(0.001)  # Reduced from 0.01s to 1ms
                    continue
                
                if self.enable_profiling:
                    self.profile_times['capture'] = time.perf_counter() - t_capture_start
                
                # å¸§è·³è¿‡é€»è¾‘ï¼ˆä»…åœ¨æ£€æµ‹å’Œè¿½è¸ªæ—¶è·³è¿‡ï¼Œå§‹ç»ˆæ›´æ–°æ˜¾ç¤ºï¼‰
                skip_processing = False
                if self.frame_skip > 0:
                    self.frame_skip_counter += 1
                    if self.frame_skip_counter <= self.frame_skip:
                        skip_processing = True
                    else:
                        self.frame_skip_counter = 0
                
                # æ›´æ–°åŸå§‹å¸§å°ºå¯¸
                self.original_frame_height, self.original_frame_width = frame.shape[:2]
                
                # æ›´æ–°è®¡æ•°çº¿ä½ç½®å’ŒROIåŒºåŸŸ
                self.update_count_line_and_roi(frame)
                
                # æ›´æ–°FPS - è®¡ç®—å®é™…å¤„ç†å¸§ç‡
                self.frame_count += 1
                current_time = time.time()
                elapsed = current_time - self.last_fps_time
                if elapsed >= 1.0:
                    # è®¡ç®—æ¯ç§’å®é™…å¤„ç†å¸§æ•°
                    self.stats['fps'] = self.frame_count / elapsed
                    self.frame_count = 0
                    self.last_fps_time = current_time
                
                t_cap_host = time.monotonic()
                
                # æ—¶é—´å¯¹é½ - å®‰å…¨è®¿é—® ctrl_buf
                s_cap, v_cap, age = (0, 0, 999)
                if self.ctrl_buf:
                    result = self.ctrl_buf.query_s_at_host_time(t_cap_host)
                    if result[0] is not None:
                        s_cap, v_cap, age = result
                
                # é—¨æ§çŠ¶æ€ï¼š
                # - å¦‚æœ UART æ¥æ”¶å…³é—­æˆ–ä¸²å£ä¸å¯ç”¨ï¼Œåˆ™é»˜è®¤é—¨æ§å¼€å¯ï¼ˆå…è®¸è¯†åˆ«ï¼‰
                # - å¦åˆ™æŒ‰åŸæœ‰é—¨æ§é€»è¾‘åŸºäºæœ€æ–° CTRL æ•°æ®
                if (not self.enable_uart_rx) or (not SERIAL_AVAILABLE):
                    gate_state = True
                else:
                    gate_state = False
                    if age <= GATE_MAX_AGE and self.ctrl_buf:
                        gate_state = self.ctrl_buf.gate_enabled(max_age=GATE_MAX_AGE)
                
                self.stats['gate_state'] = gate_state
                self.stats['s_mm'] = s_cap
                self.stats['v_mmps'] = v_cap
                
                # é•¿å›¾æ‹¼æ¥é€»è¾‘
                if self.enable_uart_rx and SERIAL_AVAILABLE:
                    # UART æ¨¡å¼ï¼šé€Ÿåº¦>0 å¼€å§‹/ç»§ç»­æ‹¼æ¥ï¼›<=0 åœæ­¢å¹¶è¯†åˆ«
                    if v_cap > 0:
                        if not self.long_capturing:
                            self._start_long_capture(reason="uart_positive_speed")
                        self._append_long_frame(frame)
                    else:
                        if self.long_capturing and self.long_reason == "uart_positive_speed":
                            self._finalize_long_capture(trigger="uart_speed_non_positive")
                # UART å…³é—­æ—¶ä¸è‡ªåŠ¨æ§åˆ¶ï¼Œç”±å¿«æ·é”®/æŒ‰é’®è§¦å‘

                # æ£€æµ‹ - å…³é”®ä¿®æ”¹ï¼šå¯ç”¨è®¡æ•°æ—¶åªè¯†åˆ«ROIåŒºåŸŸï¼Œä¸å¯ç”¨æ—¶å…¨å±è¯†åˆ«
                detections = []
                t_detect_start = time.perf_counter() if self.enable_profiling else 0
                
                if not skip_processing and self.enable_detection and gate_state and self.detector:
                    try:
                        # æ ¹æ®æ˜¯å¦å¯ç”¨è®¡æ•°å†³å®šè¯†åˆ«åŒºåŸŸ
                        detections = self.detector.infer(frame, self.roi_rect, self.downsample_ratio)
                        # åº”ç”¨æœ€å¤§æ£€æµ‹æ•°é‡é™åˆ¶
                        if len(detections) > self.max_detections:
                            detections = detections[:self.max_detections]
                    except Exception as e:
                        print(f"âš ï¸ æ£€æµ‹å¤±è´¥: {e}")
                
                if self.enable_profiling:
                    self.profile_times['detection'] = time.perf_counter() - t_detect_start
                
                self.stats['detections'] = len(detections)
                
                # è¿½è¸ª
                tracked = []
                t_track_start = time.perf_counter() if self.enable_profiling else 0
                
                if not skip_processing and self.enable_tracking and self.tracker:
                    tracked = self.tracker.update(detections)
                
                if self.enable_profiling:
                    self.profile_times['tracking'] = time.perf_counter() - t_track_start
                
                self.stats['tracked'] = len(tracked)
                
                # è¿‡çº¿è®¡æ•°
                new_cnt = 0
                if self.enable_counting and self.enable_tracking:
                    new_cnt, self.counted_objects = check_crossing_strict_direction(
                        tracked, self.count_line_y, self.counted_objects, 
                        self.counting_direction, count_zone=self.count_zone
                    )
                    self.stats['counted'] = len(self.counted_objects)
                
                # å¯†åº¦æ£€æµ‹
                if self.enable_density_detection and self.density_detector:
                    total_dets = len(detections)
                    if total_dets >= MIN_DETS_FOR_DENSITY:
                        density_map = self.density_detector.compute_density_map(detections, self.roi_rect)
                        segs, col_sum, mean, thr = self.density_detector.low_density_columns(density_map)
                        has_low = len(segs) > 0
                    else:
                        has_low = False
                    
                    self.stats['low_density'] = has_low
                    
                    seg = self.density_detector.update_segment_state(has_low, s_cap, 
                                                                    seed_count_frame=len(detections))
                    if seg and self.event_sender:
                        try:
                            s_start, s_end, seed_sum = seg
                            weight_g = seed_count_to_grams(seed_sum, SEED_TKW_GRAMS)
                            weight_mg = grams_to_mg_u32(weight_g)
                            
                            if self.seg_cache:
                                self.seg_cache.add_segment(
                                    s_start=s_start,
                                    s_end=s_end,
                                    seed_count_sum=seed_sum,
                                    weight_mg=weight_mg
                                )
                            
                            self.event_sender.send_low_density_segment(
                                event_id=self.event_id,
                                severity=255,
                                s_start_mm=s_start,
                                s_end_mm=s_end,
                                seed_count=seed_sum,
                                weight_mg=weight_mg
                            )
                            self.event_id = (self.event_id + 1) & 0xFFFF
                        except Exception as e:
                            print(f"âš ï¸ å‘é€å¯†åº¦äº‹ä»¶å¤±è´¥: {e}")
                
                # ç»˜åˆ¶æ£€æµ‹ç»“æœï¼ˆä¸æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ï¼‰
                t_draw_start = time.perf_counter() if self.enable_profiling else 0
                display_frame = self.draw_detections_simple(frame, detections, tracked, gate_state)
                if self.enable_profiling:
                    self.profile_times['drawing'] = time.perf_counter() - t_draw_start
                
                # å‘é€å¤„ç†åçš„å¸§å’Œç»Ÿè®¡ä¿¡æ¯
                self.frame_processed.emit(display_frame, self.stats.copy())
                
                # è®°å½•å®Œæ•´å¾ªç¯æ—¶é—´
                if self.enable_profiling:
                    self.profile_times['total'] = time.perf_counter() - t_loop_start
                    # å¯é€‰ï¼šå®šæœŸæ‰“å°æ€§èƒ½æ•°æ®
                    if self.frame_count % 30 == 0:  # æ¯30å¸§æ‰“å°ä¸€æ¬¡
                        print(f"[æ€§èƒ½åˆ†æ] æ•è·:{self.profile_times['capture']*1000:.1f}ms "
                              f"æ£€æµ‹:{self.profile_times['detection']*1000:.1f}ms "
                              f"è¿½è¸ª:{self.profile_times['tracking']*1000:.1f}ms "
                              f"ç»˜åˆ¶:{self.profile_times['drawing']*1000:.1f}ms "
                              f"æ€»è®¡:{self.profile_times['total']*1000:.1f}ms "
                              f"FPS:{self.stats['fps']:.1f}")
                
            except Exception as e:
                print(f"å¤„ç†å¸§æ—¶å‡ºé”™: {e}")
                time.sleep(0.01)  # Reduced from 0.1s
    
    def draw_detections_simple(self, frame, detections, tracked, gate_state):
        """ç»˜åˆ¶æ£€æµ‹å’Œè¿½è¸ªç»“æœï¼ˆä¸æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ï¼‰"""
        # Optimize: Only copy frame if we need to preserve original
        # Since we're just drawing overlays for display, work directly on the frame
        display_frame = frame
        
        # ç»˜åˆ¶æ£€æµ‹æ¡†
        for det in detections:
            x1, y1, x2, y2 = det['bbox']
            conf = det['confidence']
            label = det.get('label', 'object')
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            color = (0, 255, 0) if gate_state else (128, 128, 128)  # ç»¿è‰²æˆ–ç°è‰²
            cv2.rectangle(display_frame, (x1, y1), (x2, y2), color, 2)
            
            # ç»˜åˆ¶æ ‡ç­¾
            text = f"{label} {conf:.2f}"
            cv2.putText(display_frame, text, (x1, y1 - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        # ç»˜åˆ¶è¿½è¸ªè½¨è¿¹
        for track in tracked:
            track_id = track['track_id']
            center = track['center']
            history = track.get('history', [])
            counted = track.get('counted', False)
            
            # ç»˜åˆ¶è½¨è¿¹ç‚¹
            for i in range(1, len(history)):
                pt1 = (int(history[i-1][0]), int(history[i-1][1]))
                pt2 = (int(history[i][0]), int(history[i][1]))
                cv2.line(display_frame, pt1, pt2, (0, 255, 255), 2)
            
            # ç»˜åˆ¶IDå’Œä¸­å¿ƒç‚¹
            color = (0, 0, 255) if counted else (255, 0, 0)  # çº¢è‰²=å·²è®¡æ•°ï¼Œè“è‰²=æœªè®¡æ•°
            cv2.circle(display_frame, (int(center[0]), int(center[1])), 5, color, -1)
            cv2.putText(display_frame, f"ID:{track_id}", 
                       (int(center[0]) + 10, int(center[1]) - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        # å¦‚æœå¯ç”¨è®¡æ•°ï¼Œç»˜åˆ¶ROIåŒºåŸŸ
        if self.enable_counting and self.roi_rect is not None:
            x, y, w, h = self.roi_rect
            cv2.rectangle(display_frame, (x, y), (x + w, y + h), (255, 0, 255), 2)
            roi_info = f"ROI {w}x{h}"
            cv2.putText(display_frame, roi_info, (x + 5, y + 20),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)
        
        # å¦‚æœå¯ç”¨è®¡æ•°ï¼Œç»˜åˆ¶è®¡æ•°çº¿
        if self.enable_counting:
            if self.roi_rect is not None:
                x, _, w, _ = self.roi_rect
            else:
                x, w = 0, self.original_frame_width
            
            cv2.line(display_frame, (x, self.count_line_y), 
                    (x + w, self.count_line_y), 
                    (0, 0, 255), 2)
            cv2.putText(display_frame, f"Count Line ({self.count_line_percent}%)", 
                       (x + 10, self.count_line_y - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
            
            # ç»˜åˆ¶è®¡æ•°çº¿æ‰©å±•ä¿¡æ¯
            extend_info = f"ä¸Šæ‰©:{self.count_line_top_extend}px ä¸‹æ‰©:{self.count_line_bottom_extend}px"
            if self.roi_rect is not None:
                x, y, w, h = self.roi_rect
                cv2.putText(display_frame, extend_info, (x + 10, y + h - 10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)
        
        # ç»˜åˆ¶ä¸‹é‡‡æ ·ä¿¡æ¯ï¼ˆåªåœ¨ç”»é¢å³ä¸‹è§’æ˜¾ç¤ºï¼‰
        if self.downsample_ratio != 1.0:
            downsample_text = f"ä¸‹é‡‡æ ·:{self.downsample_ratio}x"
            cv2.putText(display_frame, downsample_text, 
                       (self.original_frame_width - 150, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)
        
        return display_frame
    
    def stop(self):
        """åœæ­¢çº¿ç¨‹"""
        self.running = False
        
        # æ¸…ç†èµ„æº - ä½¿ç”¨å®‰å…¨è®¿é—®æ–¹å¼
        try:
            if self.cam:
                self.cam.close()
        except Exception as e:
            print(f"å…³é—­ç›¸æœºæ—¶å‡ºé”™: {e}")
        
        # å®‰å…¨åœæ­¢UARTæ¥æ”¶å™¨
        try:
            if hasattr(self, 'uart_rx') and self.uart_rx:
                self.uart_rx.stop()
        except Exception as e:
            print(f"åœæ­¢UARTæ¥æ”¶å™¨æ—¶å‡ºé”™: {e}")
        
        # å®‰å…¨åœæ­¢UARTå‘é€å™¨
        try:
            if hasattr(self, 'event_sender') and self.event_sender:
                self.event_sender.stop()
        except Exception as e:
            print(f"åœæ­¢UARTå‘é€å™¨æ—¶å‡ºé”™: {e}")
        
        # å®‰å…¨åœæ­¢ç¼“å­˜çº¿ç¨‹
        try:
            if self.seg_cache:
                self.seg_cache.stop()
        except Exception as e:
            print(f"åœæ­¢ç¼“å­˜çº¿ç¨‹æ—¶å‡ºé”™: {e}")
        
        self.wait()


# ===== ä¸»çª—å£ =====
class MainWindow(QMainWindow):
    """ä¸»çª—å£ï¼ŒåŒ…å«ä¸‰ä¸ªé¡µé¢"""
    
    def __init__(self):
        super().__init__()
        
        # è·å–å±å¹•å°ºå¯¸
        screen = QApplication.primaryScreen()
        screen_geometry = screen.availableGeometry()
        self.screen_width = screen_geometry.width()
        self.screen_height = screen_geometry.height()
        
        print(f"ğŸ“º å±å¹•å°ºå¯¸: {self.screen_width}x{self.screen_height}")
        
        # æ ¹æ®å±å¹•å°ºå¯¸è®¾ç½®çª—å£å¤§å°ï¼ˆç•™å‡ºè¾¹è·ï¼‰
        window_width = min(1400, self.screen_width - 50)
        window_height = min(900, self.screen_height - 50)
        
        # çª—å£è®¾ç½®
        self.setWindowTitle("ç§å­æ£€æµ‹ç³»ç»Ÿ - MVSç›¸æœº + YOLOæ£€æµ‹")
        self.setGeometry(50, 50, window_width, window_height)
        
        # æ£€æµ‹ç³»ç»Ÿç»„ä»¶
        self.camera_thread = None
        self.current_model_path = None
        
        # é…ç½®å‚æ•°
        self.base_save_dir = DEFAULT_SAVE_DIR
        self.hotkey_start = DEFAULT_HOTKEY_START
        self.hotkey_stop = DEFAULT_HOTKEY_STOP
        
        # è§†é¢‘æ˜¾ç¤ºç›¸å…³
        self.video_width = 1280  # é»˜è®¤è§†é¢‘å®½åº¦
        self.video_height = 720  # é»˜è®¤è§†é¢‘é«˜åº¦
        self.display_scale = 1.0  # æ˜¾ç¤ºç¼©æ”¾æ¯”ä¾‹
        self.fit_to_window = True  # é»˜è®¤é€‚åº”çª—å£æ¨¡å¼
        
        # è®¡æ•°çº¿å‚æ•°
        self.count_line_percent = COUNT_LINE_PERCENT_DEFAULT
        self.count_line_top_extend = COUNT_LINE_TOP_EXTEND_DEFAULT
        self.count_line_bottom_extend = COUNT_LINE_BOTTOM_EXTEND_DEFAULT
        
        # ä¸‹é‡‡æ ·å‚æ•°
        self.downsample_ratio = DOWNSAMPLE_RATIO_DEFAULT
        
        # æ€§èƒ½ä¼˜åŒ–å‚æ•°
        self.frame_skip = 0
        self.enable_profiling = False
        
        # åˆå§‹åŒ–UI
        self.init_ui()
        
        # çŠ¶æ€æ 
        self.status_label = QLabel("å°±ç»ª")
        self.statusBar().addWidget(self.status_label)
        
        # å®šæ—¶å™¨æ›´æ–°UI
        self.update_timer = QTimer()
        self.update_timer.timeout.connect(self.update_status)
        self.update_timer.start(UI_UPDATE_INTERVAL)
    
    def init_ui(self):
        """åˆå§‹åŒ–ç”¨æˆ·ç•Œé¢"""
        # åˆ›å»ºä¸­å¤®éƒ¨ä»¶
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        # ä¸»å¸ƒå±€
        main_layout = QVBoxLayout(central_widget)
        
        # å·¥å…·æ 
        self.toolbar = self.addToolBar("å·¥å…·æ ")
        self.toolbar.setMovable(False)
        
        # å¯åŠ¨/åœæ­¢æŒ‰é’®
        self.start_btn = QPushButton("å¯åŠ¨ç³»ç»Ÿ")
        self.start_btn.clicked.connect(self.toggle_system)
        self.toolbar.addWidget(self.start_btn)
        
        # æ·»åŠ åˆ†éš”çº¿
        self.toolbar.addSeparator()
        
        # å…¨å±æŒ‰é’®
        self.fullscreen_btn = QPushButton("å…¨å±æ˜¾ç¤º")
        self.fullscreen_btn.clicked.connect(self.toggle_fullscreen)
        self.toolbar.addWidget(self.fullscreen_btn)
        
        # æˆªå±æŒ‰é’®ï¼ˆæ–°å¢ï¼‰
        self.screenshot_btn = QPushButton("æˆªå±")
        self.screenshot_btn.clicked.connect(self.capture_screen)
        self.screenshot_btn.setToolTip("æˆªå–ç¨‹åºå…¨å±ç•Œé¢")
        self.toolbar.addWidget(self.screenshot_btn)
        
        # æ·»åŠ åˆ†éš”çº¿
        self.toolbar.addSeparator()
        
        # æ ‡ç­¾é¡µ
        self.tab_widget = QTabWidget()
        main_layout.addWidget(self.tab_widget)
        
        # åˆ›å»ºé…ç½®é¡µ
        self.config_tab = self.create_config_tab()
        self.tab_widget.addTab(self.config_tab, "ç³»ç»Ÿé…ç½®")
        
        # åˆ›å»ºè§†é¢‘é¡µ
        self.video_tab = self.create_video_tab()
        self.tab_widget.addTab(self.video_tab, "è§†é¢‘æ˜¾ç¤º")
        
        # åˆ›å»ºé•¿å›¾è¯†åˆ«é¡µ
        self.long_tab = self.create_long_tab()
        self.tab_widget.addTab(self.long_tab, "é•¿å›¾è¯†åˆ«")
        
        # åˆ›å»ºçŠ¶æ€é¡µ
        self.status_tab = self.create_status_tab()
        self.tab_widget.addTab(self.status_tab, "ç³»ç»ŸçŠ¶æ€")
    
    def toggle_fullscreen(self):
        """åˆ‡æ¢å…¨å±æ¨¡å¼"""
        if self.isFullScreen():
            self.showNormal()
            self.fullscreen_btn.setText("å…¨å±æ˜¾ç¤º")
        else:
            self.showFullScreen()
            self.fullscreen_btn.setText("é€€å‡ºå…¨å±")
    
    def capture_screen(self):
        """æˆªå–ç¨‹åºå…¨å±ç•Œé¢"""
        try:
            # ä½¿ç”¨QScreen.grabWindowæˆªå–å½“å‰çª—å£
            screen = QApplication.primaryScreen()
            pixmap = screen.grabWindow(self.winId())
            
            # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
            save_dir = self.base_save_dir
            if not os.path.exists(save_dir):
                os.makedirs(save_dir, exist_ok=True)
            
            # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = os.path.join(save_dir, f"screenshot_{timestamp}.png")
            
            # ä¿å­˜æˆªå›¾
            if pixmap.save(filename, "PNG"):
                self.log_event(f"æˆªå±å·²ä¿å­˜: {filename}")
                self.status_label.setText(f"æˆªå±å·²ä¿å­˜: {os.path.basename(filename)}")
                
                # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
                QMessageBox.information(self, "æˆªå±æˆåŠŸ", 
                                      f"æˆªå±å·²ä¿å­˜åˆ°:\n{filename}\n\nä¿å­˜ç›®å½•: {save_dir}")
            else:
                self.log_event("æˆªå±ä¿å­˜å¤±è´¥")
                QMessageBox.warning(self, "æˆªå±å¤±è´¥", "æˆªå±ä¿å­˜å¤±è´¥")
                
        except Exception as e:
            self.log_event(f"æˆªå±å¤±è´¥: {e}")
            QMessageBox.critical(self, "æˆªå±é”™è¯¯", f"æˆªå±æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    def create_config_tab(self):
        """åˆ›å»ºé…ç½®é¡µé¢"""
        config_tab = QWidget()
        layout = QVBoxLayout(config_tab)
        
        # åˆ›å»ºæ»šåŠ¨åŒºåŸŸ
        scroll = QScrollArea()
        scroll.setWidgetResizable(True)
        scroll_content = QWidget()
        scroll_layout = QVBoxLayout(scroll_content)
        
        # ===== æ¨¡å‹é…ç½®ç»„ =====
        model_group = QGroupBox("æ¨¡å‹é…ç½®")
        model_layout = QGridLayout()
        
        # æ¨¡å‹é€‰æ‹©
        model_layout.addWidget(QLabel("æ¨¡å‹æ–‡ä»¶:"), 0, 0)
        self.model_combo = QComboBox()
        for model in MODEL_CANDIDATES:
            self.model_combo.addItem(model)
        self.model_combo.setCurrentText(os.path.basename(DEFAULT_MODEL_PATH))
        model_layout.addWidget(self.model_combo, 0, 1)
        
        # æ¨¡å‹æ‰‹åŠ¨è¾“å…¥
        self.model_edit = QLineEdit(DEFAULT_MODEL_PATH)
        self.model_edit.setPlaceholderText("æˆ–è¾“å…¥æ¨¡å‹æ–‡ä»¶è·¯å¾„...")
        model_layout.addWidget(self.model_edit, 0, 2)
        
        # æµè§ˆæŒ‰é’®
        browse_btn = QPushButton("æµè§ˆ...")
        browse_btn.clicked.connect(self.browse_model)
        model_layout.addWidget(browse_btn, 0, 3)
        
        # YOLOå‚æ•°
        model_layout.addWidget(QLabel("ç½®ä¿¡åº¦é˜ˆå€¼:"), 1, 0)
        self.conf_spin = QDoubleSpinBox()
        self.conf_spin.setRange(0.01, 1.0)
        self.conf_spin.setValue(0.15)
        self.conf_spin.setSingleStep(0.05)
        model_layout.addWidget(self.conf_spin, 1, 1)
        
        model_layout.addWidget(QLabel("IOUé˜ˆå€¼:"), 1, 2)
        self.iou_spin = QDoubleSpinBox()
        self.iou_spin.setRange(0.01, 1.0)
        self.iou_spin.setValue(0.10)
        self.iou_spin.setSingleStep(0.05)
        model_layout.addWidget(self.iou_spin, 1, 3)
        
        # æœ€å¤§æ£€æµ‹æ•°é‡
        model_layout.addWidget(QLabel("æœ€å¤§æ£€æµ‹æ•°:"), 2, 0)
        self.max_det_spin = QSpinBox()
        self.max_det_spin.setRange(1, 50000)
        self.max_det_spin.setValue(MAX_DETECTIONS)
        self.max_det_spin.setSingleStep(100)
        model_layout.addWidget(self.max_det_spin, 2, 1)
        
        # YOLO26 NMSå¼€å…³
        model_layout.addWidget(QLabel("å¯ç”¨NMS(YOLO26):"), 2, 2)
        self.nms_check = QCheckBox()
        self.nms_check.setChecked(USE_NMS_FOR_YOLO26)
        model_layout.addWidget(self.nms_check, 2, 3)
        
        model_group.setLayout(model_layout)
        scroll_layout.addWidget(model_group)
        
        # ===== åŠŸèƒ½å¼€å…³ç»„ =====
        func_group = QGroupBox("åŠŸèƒ½å¼€å…³")
        func_layout = QGridLayout()
        
        # æ£€æµ‹å¼€å…³
        self.detection_check = QCheckBox("å¯ç”¨æ£€æµ‹")
        self.detection_check.setChecked(True)
        func_layout.addWidget(self.detection_check, 0, 0)
        
        # è¿½è¸ªå¼€å…³
        self.tracking_check = QCheckBox("å¯ç”¨è¿½è¸ª")
        self.tracking_check.setChecked(True)
        func_layout.addWidget(self.tracking_check, 0, 1)
        
        # è®¡æ•°å¼€å…³
        self.counting_check = QCheckBox("å¯ç”¨è¿‡çº¿è®¡æ•°")
        self.counting_check.setChecked(True)
        func_layout.addWidget(self.counting_check, 0, 2)
        
        # å¯†åº¦æ£€æµ‹å¼€å…³
        self.density_check = QCheckBox("å¯ç”¨å¯†åº¦æ£€æµ‹")
        self.density_check.setChecked(DENSITY_ENABLED_DEFAULT)
        func_layout.addWidget(self.density_check, 0, 3)
        
        # UARTæ¥æ”¶å¼€å…³
        self.uart_rx_check = QCheckBox("å¯ç”¨UARTæ¥æ”¶")
        self.uart_rx_check.setChecked(True)
        func_layout.addWidget(self.uart_rx_check, 1, 0)
        
        # UARTå‘é€å¼€å…³
        self.uart_tx_check = QCheckBox("å¯ç”¨UARTå‘é€")
        self.uart_tx_check.setChecked(True)
        func_layout.addWidget(self.uart_tx_check, 1, 1)
        
        func_group.setLayout(func_layout)
        scroll_layout.addWidget(func_group)
        
        # ===== è®¡æ•°é…ç½®ç»„ =====
        count_group = QGroupBox("è®¡æ•°é…ç½®")
        count_layout = QGridLayout()
        
        # è®¡æ•°çº¿ä½ç½®ç™¾åˆ†æ¯”
        count_layout.addWidget(QLabel("è®¡æ•°çº¿ä½ç½®(%):"), 0, 0)
        self.count_line_percent_spin = QDoubleSpinBox()
        self.count_line_percent_spin.setRange(0.1, 100.0)
        self.count_line_percent_spin.setValue(self.count_line_percent)
        self.count_line_percent_spin.setSingleStep(0.5)
        count_layout.addWidget(self.count_line_percent_spin, 0, 1)
        
        # è®¡æ•°æ–¹å‘
        count_layout.addWidget(QLabel("è®¡æ•°æ–¹å‘:"), 0, 2)
        self.direction_combo = QComboBox()
        self.direction_combo.addItems(["å‘ä¸Š", "å‘ä¸‹"])
        self.direction_combo.setCurrentText("å‘ä¸‹")
        count_layout.addWidget(self.direction_combo, 0, 3)
        
        # ROIå‘ä¸Šæ‰©å±•åƒç´ æ•°
        count_layout.addWidget(QLabel("ROIå‘ä¸Šæ‰©å±•(px):"), 1, 0)
        self.roi_top_spin = QSpinBox()
        self.roi_top_spin.setRange(1, 1000)
        self.roi_top_spin.setValue(self.count_line_top_extend)
        count_layout.addWidget(self.roi_top_spin, 1, 1)
        
        # ROIå‘ä¸‹æ‰©å±•åƒç´ æ•°
        count_layout.addWidget(QLabel("ROIå‘ä¸‹æ‰©å±•(px):"), 1, 2)
        self.roi_bottom_spin = QSpinBox()
        self.roi_bottom_spin.setRange(1, 1000)
        self.roi_bottom_spin.setValue(self.count_line_bottom_extend)
        count_layout.addWidget(self.roi_bottom_spin, 1, 3)
        
        count_group.setLayout(count_layout)
        scroll_layout.addWidget(count_group)
        
        # ===== ä¸‹é‡‡æ ·é…ç½®ç»„ =====
        downsample_group = QGroupBox("ç”»é¢ä¸‹é‡‡æ ·é…ç½®")
        downsample_layout = QGridLayout()
        
        # ä¸‹é‡‡æ ·æ¯”ä¾‹é€‰æ‹©
        downsample_layout.addWidget(QLabel("ä¸‹é‡‡æ ·æ¯”ä¾‹:"), 0, 0)
        self.downsample_combo = QComboBox()
        for ratio in DOWNSAMPLE_OPTIONS:
            self.downsample_combo.addItem(f"{ratio:.2f}")
        self.downsample_combo.setCurrentText(f"{self.downsample_ratio:.2f}")
        downsample_layout.addWidget(self.downsample_combo, 0, 1)
        
        # ä¸‹é‡‡æ ·è¯´æ˜
        downsample_layout.addWidget(QLabel("è¯´æ˜: 1.0=ä¸ä¸‹é‡‡æ ·, 0.5=ç¼©å°ä¸€åŠ, 0.25=ç¼©å°åˆ°1/4"), 0, 2, 1, 2)
        
        downsample_group.setLayout(downsample_layout)
        scroll_layout.addWidget(downsample_group)
        
        # ===== æ€§èƒ½ä¼˜åŒ–é…ç½®ç»„ =====
        perf_group = QGroupBox("æ€§èƒ½ä¼˜åŒ–é…ç½®")
        perf_layout = QGridLayout()
        
        # å¸§è·³è¿‡é…ç½®
        perf_layout.addWidget(QLabel("å¸§è·³è¿‡æ•°:"), 0, 0)
        self.frame_skip_spin = QSpinBox()
        self.frame_skip_spin.setRange(0, 10)
        self.frame_skip_spin.setValue(0)
        self.frame_skip_spin.setToolTip("0=å¤„ç†æ‰€æœ‰å¸§, 1=è·³è¿‡1å¸§å¤„ç†1å¸§, 2=è·³è¿‡2å¸§å¤„ç†1å¸§")
        perf_layout.addWidget(self.frame_skip_spin, 0, 1)
        
        # æ€§èƒ½åˆ†æå¼€å…³
        self.enable_profiling_check = QCheckBox("å¯ç”¨æ€§èƒ½åˆ†æ")
        self.enable_profiling_check.setChecked(False)
        self.enable_profiling_check.setToolTip("å¯ç”¨åä¼šåœ¨æ§åˆ¶å°æ‰“å°è¯¦ç»†çš„æ€§èƒ½æ•°æ®")
        perf_layout.addWidget(self.enable_profiling_check, 0, 2, 1, 2)
        
        # è¯´æ˜
        perf_layout.addWidget(QLabel("è¯´æ˜: å¸§è·³è¿‡å¯ä»¥åœ¨æç«¯èµ„æºå—é™æ—¶ä½¿ç”¨ï¼Œä»¥ç‰ºç‰²æ£€æµ‹è¿ç»­æ€§æ¢å–FPS"), 1, 0, 1, 4)
        
        perf_group.setLayout(perf_layout)
        scroll_layout.addWidget(perf_group)
        
        # ===== åƒç²’é‡é…ç½®ç»„ =====
        tkw_group = QGroupBox("åƒç²’é‡é…ç½®")
        tkw_layout = QGridLayout()
        
        # åƒç²’é‡é…ç½®
        tkw_layout.addWidget(QLabel("åƒç²’é‡(g):"), 0, 0)
        self.tkw_spin = QDoubleSpinBox()
        self.tkw_spin.setRange(0.1, 1000.0)
        self.tkw_spin.setValue(SEED_TKW_GRAMS)
        self.tkw_spin.setSingleStep(1.0)
        tkw_layout.addWidget(self.tkw_spin, 0, 1)
        
        tkw_group.setLayout(tkw_layout)
        scroll_layout.addWidget(tkw_group)
        
        # ===== å¯†åº¦æ£€æµ‹é…ç½®ç»„ =====
        density_group = QGroupBox("å¯†åº¦æ£€æµ‹é…ç½®")
        density_layout = QGridLayout()
        
        # ç½‘æ ¼åˆ—æ•°
        density_layout.addWidget(QLabel("ç½‘æ ¼åˆ—æ•°:"), 0, 0)
        self.grid_cols_spin = QSpinBox()
        self.grid_cols_spin.setRange(1, 50)
        self.grid_cols_spin.setValue(DENSITY_GRID_COLS)
        density_layout.addWidget(self.grid_cols_spin, 0, 1)
        
        # ç½‘æ ¼è¡Œæ•°
        density_layout.addWidget(QLabel("ç½‘æ ¼è¡Œæ•°:"), 0, 2)
        self.grid_rows_spin = QSpinBox()
        self.grid_rows_spin.setRange(1, 50)
        self.grid_rows_spin.setValue(DENSITY_GRID_ROWS)
        density_layout.addWidget(self.grid_rows_spin, 0, 3)
        
        # ä½å¯†åº¦é˜ˆå€¼
        density_layout.addWidget(QLabel("ä½å¯†åº¦æ¯”ä¾‹:"), 1, 0)
        self.low_ratio_spin = QDoubleSpinBox()
        self.low_ratio_spin.setRange(0.01, 1.0)
        self.low_ratio_spin.setValue(LOW_DENSITY_RATIO)
        self.low_ratio_spin.setSingleStep(0.05)
        density_layout.addWidget(self.low_ratio_spin, 1, 1)
        
        # æœ€å°æ£€æµ‹æ•°
        density_layout.addWidget(QLabel("æœ€å°æ£€æµ‹æ•°:"), 1, 2)
        self.min_dets_spin = QSpinBox()
        self.min_dets_spin.setRange(1, 100)
        self.min_dets_spin.setValue(MIN_DETS_FOR_DENSITY)
        density_layout.addWidget(self.min_dets_spin, 1, 3)
        
        density_group.setLayout(density_layout)
        scroll_layout.addWidget(density_group)
        
        # ===== UARTé…ç½®ç»„ =====
        uart_group = QGroupBox("ä¸²å£é…ç½®")
        uart_layout = QGridLayout()
        
        # ä¸²å£ç«¯å£
        uart_layout.addWidget(QLabel("ä¸²å£ç«¯å£:"), 0, 0)
        self.uart_port_edit = QLineEdit(UART_PORT)
        uart_layout.addWidget(self.uart_port_edit, 0, 1)
        
        # æ³¢ç‰¹ç‡
        uart_layout.addWidget(QLabel("æ³¢ç‰¹ç‡:"), 0, 2)
        self.baud_combo = QComboBox()
        self.baud_combo.addItems(["9600", "19200", "38400", "57600", "115200", "921600"])
        self.baud_combo.setCurrentText(str(UART_BAUD))
        uart_layout.addWidget(self.baud_combo, 0, 3)
        
        # é—¨æ§æœ€å¤§å¹´é¾„
        uart_layout.addWidget(QLabel("é—¨æ§è¶…æ—¶(ç§’):"), 1, 0)
        self.gate_age_spin = QDoubleSpinBox()
        self.gate_age_spin.setRange(0.1, 10.0)
        self.gate_age_spin.setValue(GATE_MAX_AGE)
        self.gate_age_spin.setSingleStep(0.1)
        uart_layout.addWidget(self.gate_age_spin, 1, 1)
        
        uart_group.setLayout(uart_layout)
        scroll_layout.addWidget(uart_group)

        # ===== ä¿å­˜ä¸å¿«æ·é”®é…ç½®ç»„ =====
        save_group = QGroupBox("é•¿å›¾ä¸å¿«æ·é”®é…ç½®")
        save_layout = QGridLayout()
        save_layout.addWidget(QLabel("ä¿å­˜æ ¹ç›®å½•:"), 0, 0)
        self.save_dir_edit = QLineEdit(self.base_save_dir)
        save_layout.addWidget(self.save_dir_edit, 0, 1, 1, 3)
        save_layout.addWidget(QLabel("å¼€å§‹æ‹¼æ¥å¿«æ·é”®:"), 1, 0)
        self.hotkey_start_edit = QLineEdit(self.hotkey_start)
        self.hotkey_start_edit.setMaxLength(1)
        save_layout.addWidget(self.hotkey_start_edit, 1, 1)
        save_layout.addWidget(QLabel("ç»“æŸæ‹¼æ¥å¿«æ·é”®:"), 1, 2)
        self.hotkey_stop_edit = QLineEdit(self.hotkey_stop)
        self.hotkey_stop_edit.setMaxLength(1)
        save_layout.addWidget(self.hotkey_stop_edit, 1, 3)
        save_group.setLayout(save_layout)
        scroll_layout.addWidget(save_group)
        
        # ===== åº”ç”¨æŒ‰é’® =====
        button_layout = QHBoxLayout()
        apply_btn = QPushButton("åº”ç”¨é…ç½®")
        apply_btn.clicked.connect(self.apply_config)
        apply_btn.setStyleSheet("background-color: #4CAF50; color: white; font-weight: bold;")
        button_layout.addWidget(apply_btn)
        
        reset_btn = QPushButton("æ¢å¤é»˜è®¤")
        reset_btn.clicked.connect(self.reset_config)
        reset_btn.setStyleSheet("background-color: #f44336; color: white;")
        button_layout.addWidget(reset_btn)
        
        scroll_layout.addLayout(button_layout)
        
        # è®¾ç½®æ»šåŠ¨åŒºåŸŸå†…å®¹
        scroll.setWidget(scroll_content)
        layout.addWidget(scroll)
        
        return config_tab
    
    def create_video_tab(self):
        """åˆ›å»ºè§†é¢‘æ˜¾ç¤ºé¡µé¢"""
        video_tab = QWidget()
        layout = QVBoxLayout(video_tab)
        layout.setContentsMargins(5, 5, 5, 5)
        
        # åˆ›å»ºæ»šåŠ¨åŒºåŸŸç”¨äºè§†é¢‘æ˜¾ç¤º
        scroll_area = QScrollArea()
        scroll_area.setWidgetResizable(True)
        scroll_area.setHorizontalScrollBarPolicy(Qt.ScrollBarAsNeeded)
        scroll_area.setVerticalScrollBarPolicy(Qt.ScrollBarAsNeeded)
        scroll_area.setFrameShape(QFrame.NoFrame)
        
        # è§†é¢‘æ˜¾ç¤ºåŒºåŸŸ
        self.video_container = QWidget()
        self.video_layout = QVBoxLayout(self.video_container)
        self.video_layout.setContentsMargins(0, 0, 0, 0)
        self.video_layout.setSpacing(5)
        
        self.video_label = QLabel()
        self.video_label.setAlignment(Qt.AlignCenter)
        
        # è®¡ç®—é€‚åˆå±å¹•çš„åˆå§‹æœ€å°å°ºå¯¸
        min_width = min(640, self.screen_width - 100)
        min_height = min(360, self.screen_height - 200)
        self.video_label.setMinimumSize(min_width, min_height)
        
        self.video_label.setScaledContents(False)
        self.video_label.setStyleSheet("""
            QLabel {
                background-color: black;
                border: 1px solid #333;
            }
        """)
        
        # æ·»åŠ å°ºå¯¸æ ‡ç­¾
        self.size_label = QLabel("åŸå§‹å°ºå¯¸: 1280x720")
        self.size_label.setAlignment(Qt.AlignCenter)
        self.size_label.setStyleSheet("color: #888; font-size: 9pt; padding: 2px;")
        
        self.video_layout.addWidget(self.video_label, 0, Qt.AlignCenter)
        self.video_layout.addWidget(self.size_label, 0, Qt.AlignCenter)
        self.video_layout.addStretch()
        
        # è®¾ç½®æ»šåŠ¨åŒºåŸŸçš„å†…å®¹
        scroll_area.setWidget(self.video_container)
        layout.addWidget(scroll_area)
        
        # æ§åˆ¶æŒ‰é’®åŒºåŸŸ
        control_layout = QHBoxLayout()
        control_layout.setSpacing(10)
        
        # æ˜¾ç¤ºæ¨¡å¼åˆ‡æ¢æŒ‰é’®
        self.display_mode_btn = QPushButton("é€‚åº”çª—å£")
        self.display_mode_btn.setFixedWidth(100)
        self.display_mode_btn.clicked.connect(self.toggle_display_mode)
        self.display_mode_btn.setStyleSheet("background-color: #4CAF50; color: white;")
        control_layout.addWidget(self.display_mode_btn)
        
        # åŸå§‹å¤§å°æŒ‰é’®
        self.original_size_btn = QPushButton("åŸå§‹å¤§å°")
        self.original_size_btn.setFixedWidth(100)
        self.original_size_btn.clicked.connect(self.show_original_size)
        self.original_size_btn.setStyleSheet("background-color: #2196F3; color: white;")
        control_layout.addWidget(self.original_size_btn)
        
        # æ·»åŠ åˆ†éš”ç¬¦
        control_layout.addSpacing(20)
        
        # å…¶ä»–åŠŸèƒ½æŒ‰é’®
        self.record_btn = QPushButton("å¼€å§‹å½•åˆ¶")
        self.record_btn.setFixedWidth(100)
        self.record_btn.clicked.connect(self.toggle_recording)
        control_layout.addWidget(self.record_btn)
        
        self.snapshot_btn = QPushButton("æˆªå›¾")
        self.snapshot_btn.setFixedWidth(80)
        self.snapshot_btn.clicked.connect(self.take_snapshot)
        control_layout.addWidget(self.snapshot_btn)
        
        self.clear_count_btn = QPushButton("æ¸…é›¶è®¡æ•°")
        self.clear_count_btn.setFixedWidth(100)
        self.clear_count_btn.clicked.connect(self.clear_counting)
        control_layout.addWidget(self.clear_count_btn)
        
        control_layout.addStretch()
        layout.addLayout(control_layout)
        
        return video_tab

    def create_long_tab(self):
        """åˆ›å»ºé•¿å›¾è¯†åˆ«é¡µé¢"""
        tab = QWidget()
        layout = QVBoxLayout(tab)
        
        info = QLabel(
            "UART å¼€å¯ï¼šé€Ÿåº¦>0 è‡ªåŠ¨æ‹¼æ¥ï¼Œé€Ÿåº¦â‰¤0 è‡ªåŠ¨åœæ­¢å¹¶è¯†åˆ«ã€‚\n"
            "UART å…³é—­ï¼šä½¿ç”¨å¿«æ·é”®æˆ–ä¸‹æ–¹æŒ‰é’®å¼€å§‹/ç»“æŸæ‹¼æ¥ï¼Œç»“æŸåè‡ªåŠ¨è¯†åˆ«ã€‚\n"
            "ç»“æœï¼ˆåŸå›¾+è¯†åˆ«å›¾+jsonï¼‰ä¿å­˜åˆ°æ ¹ç›®å½•ä¸‹æŒ‰å¹´æœˆæ—¥æ—¶åˆ†ç§’åˆ›å»ºçš„å­ç›®å½•ã€‚"
        )
        info.setWordWrap(True)
        layout.addWidget(info)
        
        btn_layout = QHBoxLayout()
        self.long_start_btn = QPushButton("æ‰‹åŠ¨å¼€å§‹æ‹¼æ¥")
        self.long_stop_btn = QPushButton("æ‰‹åŠ¨ç»“æŸå¹¶è¯†åˆ«")
        self.long_start_btn.clicked.connect(self.manual_start_long)
        self.long_stop_btn.clicked.connect(self.manual_stop_long)
        btn_layout.addWidget(self.long_start_btn)
        btn_layout.addWidget(self.long_stop_btn)
        btn_layout.addStretch()
        layout.addLayout(btn_layout)
        
        status_layout = QHBoxLayout()
        status_layout.addWidget(QLabel("é•¿å›¾çŠ¶æ€:"))
        self.long_status_label = QLabel("ç©ºé—²")
        self.long_status_label.setStyleSheet("color: green; font-weight: bold;")
        status_layout.addWidget(self.long_status_label)
        status_layout.addStretch()
        layout.addLayout(status_layout)
        
        return tab
    
    def create_status_tab(self):
        """åˆ›å»ºç³»ç»ŸçŠ¶æ€é¡µé¢"""
        status_tab = QWidget()
        layout = QVBoxLayout(status_tab)
        
        # ç³»ç»ŸçŠ¶æ€ç»„
        sys_group = QGroupBox("ç³»ç»ŸçŠ¶æ€")
        sys_layout = QGridLayout()
        
        # ç›¸æœºçŠ¶æ€
        sys_layout.addWidget(QLabel("ç›¸æœºçŠ¶æ€:"), 0, 0)
        self.camera_status = QLabel("æœªè¿æ¥")
        self.camera_status.setStyleSheet("color: red; font-weight: bold;")
        sys_layout.addWidget(self.camera_status, 0, 1)
        
        # æ¨¡å‹çŠ¶æ€
        sys_layout.addWidget(QLabel("æ¨¡å‹çŠ¶æ€:"), 0, 2)
        self.model_status = QLabel("æœªåŠ è½½")
        self.model_status.setStyleSheet("color: red; font-weight: bold;")
        sys_layout.addWidget(self.model_status, 0, 3)
        
        # UARTæ¥æ”¶çŠ¶æ€
        sys_layout.addWidget(QLabel("UARTæ¥æ”¶:"), 1, 0)
        self.uart_rx_status = QLabel("æœªè¿æ¥")
        self.uart_rx_status.setStyleSheet("color: red; font-weight: bold;")
        sys_layout.addWidget(self.uart_rx_status, 1, 1)
        
        # UARTå‘é€çŠ¶æ€
        sys_layout.addWidget(QLabel("UARTå‘é€:"), 1, 2)
        self.uart_tx_status = QLabel("æœªè¿æ¥")
        self.uart_tx_status.setStyleSheet("color: red; font-weight: bold;")
        sys_layout.addWidget(self.uart_tx_status, 1, 3)
        
        # ç³»ç»Ÿè¿è¡Œæ—¶é—´
        sys_layout.addWidget(QLabel("è¿è¡Œæ—¶é—´:"), 2, 0)
        self.uptime_label = QLabel("00:00:00")
        sys_layout.addWidget(self.uptime_label, 2, 1)
        
        # å¸§ç‡æ˜¾ç¤º
        sys_layout.addWidget(QLabel("å¤„ç†å¸§ç‡:"), 2, 2)
        self.fps_label = QLabel("0")
        sys_layout.addWidget(self.fps_label, 2, 3)
        
        sys_group.setLayout(sys_layout)
        layout.addWidget(sys_group)
        
        # æ£€æµ‹ç»Ÿè®¡ç»„
        stats_group = QGroupBox("æ£€æµ‹ç»Ÿè®¡")
        stats_layout = QGridLayout()
        
        # æ£€æµ‹æ•°é‡
        stats_layout.addWidget(QLabel("å½“å‰æ£€æµ‹æ•°:"), 0, 0)
        self.detections_label = QLabel("0")
        stats_layout.addWidget(self.detections_label, 0, 1)
        
        # è¿½è¸ªæ•°é‡
        stats_layout.addWidget(QLabel("è¿½è¸ªç›®æ ‡æ•°:"), 0, 2)
        self.tracked_label = QLabel("0")
        stats_layout.addWidget(self.tracked_label, 0, 3)
        
        # è®¡æ•°æ•°é‡
        stats_layout.addWidget(QLabel("ç´¯è®¡è®¡æ•°:"), 1, 0)
        self.counted_label = QLabel("0")
        stats_layout.addWidget(self.counted_label, 1, 1)
        
        # ä½å¯†åº¦çŠ¶æ€
        stats_layout.addWidget(QLabel("ä½å¯†åº¦çŠ¶æ€:"), 1, 2)
        self.low_density_label = QLabel("æ­£å¸¸")
        self.low_density_label.setStyleSheet("color: green; font-weight: bold;")
        stats_layout.addWidget(self.low_density_label, 1, 3)
        
        # é—¨æ§çŠ¶æ€
        stats_layout.addWidget(QLabel("é—¨æ§çŠ¶æ€:"), 2, 0)
        self.gate_label = QLabel("å…³é—­")
        self.gate_label.setStyleSheet("color: red; font-weight: bold;")
        stats_layout.addWidget(self.gate_label, 2, 1)
        
        # é€Ÿåº¦æ˜¾ç¤º
        stats_layout.addWidget(QLabel("å½“å‰é€Ÿåº¦:"), 2, 2)
        self.speed_label = QLabel("0 mm/s")
        stats_layout.addWidget(self.speed_label, 2, 3)
        
        # ä½ç½®æ˜¾ç¤º
        stats_layout.addWidget(QLabel("å½“å‰ä½ç½®:"), 3, 0)
        self.position_label = QLabel("0 mm")
        stats_layout.addWidget(self.position_label, 3, 1)

        # é•¿å›¾çŠ¶æ€
        stats_layout.addWidget(QLabel("é•¿å›¾çŠ¶æ€:"), 3, 2)
        self.long_status_small = QLabel("ç©ºé—²")
        self.long_status_small.setStyleSheet("color: green; font-weight: bold;")
        stats_layout.addWidget(self.long_status_small, 3, 3)
        
        # è®¡æ•°çº¿çŠ¶æ€
        stats_layout.addWidget(QLabel("è®¡æ•°çº¿ä½ç½®:"), 4, 0)
        self.count_line_label = QLabel("0 px (0.0%)")
        self.count_line_label.setStyleSheet("color: blue; font-weight: bold;")
        stats_layout.addWidget(self.count_line_label, 4, 1)
        
        # ROIçŠ¶æ€
        stats_layout.addWidget(QLabel("ROIåŒºåŸŸ:"), 4, 2)
        self.roi_label = QLabel("å…¨å±")
        self.roi_label.setStyleSheet("color: blue; font-weight: bold;")
        stats_layout.addWidget(self.roi_label, 4, 3)
        
        # ä¸‹é‡‡æ ·çŠ¶æ€
        stats_layout.addWidget(QLabel("ä¸‹é‡‡æ ·:"), 5, 0)
        self.downsample_label = QLabel("1.0x")
        self.downsample_label.setStyleSheet("color: blue; font-weight: bold;")
        stats_layout.addWidget(self.downsample_label, 5, 1)
        
        # è®¡æ•°æ–¹å‘
        stats_layout.addWidget(QLabel("è®¡æ•°æ–¹å‘:"), 5, 2)
        self.counting_direction_label = QLabel("å‘ä¸‹")
        self.counting_direction_label.setStyleSheet("color: blue; font-weight: bold;")
        stats_layout.addWidget(self.counting_direction_label, 5, 3)
        
        stats_group.setLayout(stats_layout)
        layout.addWidget(stats_group)
        
        # äº‹ä»¶æ—¥å¿—ç»„
        log_group = QGroupBox("äº‹ä»¶æ—¥å¿—")
        log_layout = QVBoxLayout()
        
        self.log_text = QTextEdit()
        self.log_text.setReadOnly(True)
        self.log_text.setMaximumHeight(200)
        log_layout.addWidget(self.log_text)
        
        # æ—¥å¿—æ§åˆ¶
        log_control_layout = QHBoxLayout()
        clear_log_btn = QPushButton("æ¸…ç©ºæ—¥å¿—")
        clear_log_btn.clicked.connect(self.clear_log)
        log_control_layout.addWidget(clear_log_btn)
        
        log_control_layout.addStretch()
        log_layout.addLayout(log_control_layout)
        
        log_group.setLayout(log_layout)
        layout.addWidget(log_group)
        
        layout.addStretch()
        
        return status_tab
    
    def browse_model(self):
        """æµè§ˆæ¨¡å‹æ–‡ä»¶"""
        file_path, _ = QFileDialog.getOpenFileName(
            self, "é€‰æ‹©æ¨¡å‹æ–‡ä»¶", "", 
            "æ¨¡å‹æ–‡ä»¶ (*.engine *.onnx *.pt);;æ‰€æœ‰æ–‡ä»¶ (*.*)"
        )
        if file_path:
            self.model_edit.setText(file_path)
    
    def apply_config(self):
        """åº”ç”¨é…ç½®"""
        # è·å–æ¨¡å‹è·¯å¾„
        model_path = self.model_edit.text().strip()
        if not model_path:
            model_path = self.model_combo.currentText()
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.isfile(model_path):
            QMessageBox.warning(self, "è­¦å‘Š", f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return
        
        # ä¿å­˜å½“å‰æ¨¡å‹è·¯å¾„
        self.current_model_path = model_path
        
        # æ›´æ–°å…¨å±€é…ç½®
        global USE_NMS_FOR_YOLO26
        global MAX_DETECTIONS
        USE_NMS_FOR_YOLO26 = self.nms_check.isChecked()
        MAX_DETECTIONS = self.max_det_spin.value()
        
        # æ›´æ–°è®¡æ•°çº¿å‚æ•°
        self.count_line_percent = self.count_line_percent_spin.value()
        self.count_line_top_extend = self.roi_top_spin.value()
        self.count_line_bottom_extend = self.roi_bottom_spin.value()
        
        # æ›´æ–°ä¸‹é‡‡æ ·å‚æ•°
        self.downsample_ratio = float(self.downsample_combo.currentText())
        
        # æ›´æ–°æ€§èƒ½ä¼˜åŒ–å‚æ•°
        self.frame_skip = self.frame_skip_spin.value()
        self.enable_profiling = self.enable_profiling_check.isChecked()
        
        # ä¿å­˜è·¯å¾„ä¸å¿«æ·é”®
        self.base_save_dir = self.save_dir_edit.text().strip() or DEFAULT_SAVE_DIR
        self.hotkey_start = (self.hotkey_start_edit.text().strip() or DEFAULT_HOTKEY_START).upper()[0:1]
        self.hotkey_stop = (self.hotkey_stop_edit.text().strip() or DEFAULT_HOTKEY_STOP).upper()[0:1]

        # è®°å½•é…ç½®å˜æ›´
        self.log_event(f"åº”ç”¨é…ç½®: æ¨¡å‹={os.path.basename(model_path)}")
        self.log_event(f"  ç½®ä¿¡åº¦={self.conf_spin.value()}, IOU={self.iou_spin.value()}")
        self.log_event(f"  æœ€å¤§æ£€æµ‹æ•°={MAX_DETECTIONS}")
        self.log_event(f"  è®¡æ•°çº¿ä½ç½®={self.count_line_percent}%")
        self.log_event(f"  ROIä¸Šæ‰©={self.count_line_top_extend}px, ROIä¸‹æ‰©={self.count_line_bottom_extend}px")
        self.log_event(f"  è®¡æ•°æ–¹å‘={self.direction_combo.currentText()}")
        self.log_event(f"  ä¸‹é‡‡æ ·æ¯”ä¾‹={self.downsample_ratio:.2f}x")
        self.log_event(f"  å¸§è·³è¿‡æ•°={self.frame_skip}")
        self.log_event(f"  æ€§èƒ½åˆ†æ={'å¯ç”¨' if self.enable_profiling else 'ç¦ç”¨'}")
        self.log_event(f"  YOLO26 NMS={'å¯ç”¨' if USE_NMS_FOR_YOLO26 else 'ç¦ç”¨'}")
        self.log_event(f"  ä¿å­˜ç›®å½•={self.base_save_dir}")
        self.log_event(f"  å¿«æ·é”® å¼€å§‹={self.hotkey_start}, ç»“æŸ={self.hotkey_stop}")
        
        # å¦‚æœç³»ç»Ÿæ­£åœ¨è¿è¡Œï¼Œéœ€è¦é‡å¯
        if self.camera_thread and self.camera_thread.running:
            reply = QMessageBox.question(self, "é‡å¯ç³»ç»Ÿ", 
                                        "é…ç½®å·²æ›´æ”¹ï¼Œéœ€è¦é‡å¯ç³»ç»Ÿæ‰èƒ½ç”Ÿæ•ˆã€‚æ˜¯å¦ç°åœ¨é‡å¯?",
                                        QMessageBox.Yes | QMessageBox.No)
            if reply == QMessageBox.Yes:
                self.stop_system()
                self.start_system()
    
    def reset_config(self):
        """æ¢å¤é»˜è®¤é…ç½®"""
        reply = QMessageBox.question(self, "ç¡®è®¤", 
                                    "æ˜¯å¦æ¢å¤æ‰€æœ‰é…ç½®ä¸ºé»˜è®¤å€¼?",
                                    QMessageBox.Yes | QMessageBox.No)
        if reply == QMessageBox.Yes:
            # é‡ç½®æ‰€æœ‰æ§ä»¶
            self.model_combo.setCurrentText(os.path.basename(DEFAULT_MODEL_PATH))
            self.model_edit.setText(DEFAULT_MODEL_PATH)
            self.conf_spin.setValue(0.15)
            self.iou_spin.setValue(0.10)
            self.max_det_spin.setValue(MAX_DETECTIONS)
            self.nms_check.setChecked(USE_NMS_FOR_YOLO26)
            self.detection_check.setChecked(True)
            self.tracking_check.setChecked(True)
            self.counting_check.setChecked(True)
            self.density_check.setChecked(DENSITY_ENABLED_DEFAULT)
            self.uart_rx_check.setChecked(True)
            self.uart_tx_check.setChecked(True)
            
            # è®¡æ•°çº¿å‚æ•°
            self.count_line_percent_spin.setValue(COUNT_LINE_PERCENT_DEFAULT)
            self.direction_combo.setCurrentText("å‘ä¸‹")
            self.roi_top_spin.setValue(COUNT_LINE_TOP_EXTEND_DEFAULT)
            self.roi_bottom_spin.setValue(COUNT_LINE_BOTTOM_EXTEND_DEFAULT)
            
            # ä¸‹é‡‡æ ·å‚æ•°
            self.downsample_combo.setCurrentText(f"{DOWNSAMPLE_RATIO_DEFAULT:.2f}")
            
            self.tkw_spin.setValue(SEED_TKW_GRAMS)
            self.grid_cols_spin.setValue(DENSITY_GRID_COLS)
            self.grid_rows_spin.setValue(DENSITY_GRID_ROWS)
            self.low_ratio_spin.setValue(LOW_DENSITY_RATIO)
            self.min_dets_spin.setValue(MIN_DETS_FOR_DENSITY)
            self.uart_port_edit.setText(UART_PORT)
            self.baud_combo.setCurrentText(str(UART_BAUD))
            self.gate_age_spin.setValue(GATE_MAX_AGE)
            self.save_dir_edit.setText(DEFAULT_SAVE_DIR)
            self.hotkey_start_edit.setText(DEFAULT_HOTKEY_START)
            self.hotkey_stop_edit.setText(DEFAULT_HOTKEY_STOP)
            
            self.log_event("é…ç½®å·²æ¢å¤ä¸ºé»˜è®¤å€¼")
    
    def toggle_system(self):
        """å¯åŠ¨/åœæ­¢ç³»ç»Ÿ"""
        if self.camera_thread and self.camera_thread.running:
            self.stop_system()
        else:
            self.start_system()
    
    def start_system(self):
        """å¯åŠ¨ç³»ç»Ÿ"""
        # è·å–æ¨¡å‹è·¯å¾„
        model_path = self.model_edit.text().strip()
        if not model_path:
            model_path = self.model_combo.currentText()
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
        if not os.path.isfile(model_path):
            QMessageBox.critical(self, "é”™è¯¯", f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return
        
        # åˆ›å»ºå¹¶å¯åŠ¨ç›¸æœºçº¿ç¨‹
        self.camera_thread = CameraThread()
        
        # è®¾ç½®é…ç½®å‚æ•°
        self.camera_thread.enable_detection = self.detection_check.isChecked()
        self.camera_thread.enable_tracking = self.tracking_check.isChecked()
        self.camera_thread.enable_counting = self.counting_check.isChecked()
        self.camera_thread.enable_density_detection = self.density_check.isChecked()
        self.camera_thread.enable_uart_rx = self.uart_rx_check.isChecked()
        self.camera_thread.enable_uart_tx = self.uart_tx_check.isChecked()
        
        # è®¡æ•°çº¿å‚æ•°
        self.camera_thread.count_line_percent = self.count_line_percent_spin.value()
        self.camera_thread.count_line_top_extend = self.roi_top_spin.value()
        self.camera_thread.count_line_bottom_extend = self.roi_bottom_spin.value()
        
        # ä¸‹é‡‡æ ·å‚æ•°
        self.camera_thread.downsample_ratio = float(self.downsample_combo.currentText())
        
        # æ€§èƒ½ä¼˜åŒ–å‚æ•°
        self.camera_thread.frame_skip = self.frame_skip_spin.value()
        self.camera_thread.enable_profiling = self.enable_profiling_check.isChecked()
        
        # å…¶ä»–å‚æ•°
        self.camera_thread.counting_direction = "up" if self.direction_combo.currentText() == "å‘ä¸Š" else "down"
        self.camera_thread.max_detections = self.max_det_spin.value()
        self.camera_thread.set_base_save_dir(self.base_save_dir)
        
        # è¿æ¥ä¿¡å·
        self.camera_thread.frame_processed.connect(self.update_video_display)
        self.camera_thread.long_status_changed.connect(self.on_long_status_changed)
        
        # åˆå§‹åŒ–ç³»ç»Ÿ
        if not self.camera_thread.initialize(model_path):
            QMessageBox.critical(self, "é”™è¯¯", "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
            return
        
        # å¯åŠ¨çº¿ç¨‹
        self.camera_thread.start()
        
        # æ›´æ–°UIçŠ¶æ€
        self.start_btn.setText("åœæ­¢ç³»ç»Ÿ")
        self.start_btn.setStyleSheet("background-color: #f44336; color: white; font-weight: bold;")
        
        # è®°å½•å¯åŠ¨æ—¶é—´
        self.start_time = time.time()
        
        # æ›´æ–°çŠ¶æ€
        self.camera_status.setText("è¿è¡Œä¸­")
        self.camera_status.setStyleSheet("color: green; font-weight: bold;")
        self.model_status.setText(f"å·²åŠ è½½: {os.path.basename(model_path)}")
        self.model_status.setStyleSheet("color: green; font-weight: bold;")
        self.count_line_label.setText(f"0 px (0.0%)")
        self.roi_label.setText("å…¨å±")
        self.downsample_label.setText(f"{self.downsample_ratio:.2f}x")
        self.counting_direction_label.setText(self.direction_combo.currentText())
        
        self.log_event(f"ç³»ç»Ÿå¯åŠ¨ - æ¨¡å‹: {os.path.basename(model_path)}")
        self.log_event(f"  è®¡æ•°çº¿ä½ç½®: {self.count_line_percent}%")
        self.log_event(f"  ROIæ‰©å±•: ä¸Š{self.count_line_top_extend}px, ä¸‹{self.count_line_bottom_extend}px")
        self.log_event(f"  ä¸‹é‡‡æ ·: {self.downsample_ratio:.2f}x")
        self.log_event(f"  è®¡æ•°æ–¹å‘: {self.direction_combo.currentText()}")
        self.log_event(f"  è®¡æ•°æ¨¡å¼: {'å¯ç”¨' if self.counting_check.isChecked() else 'ç¦ç”¨'}")
    
    def stop_system(self):
        """åœæ­¢ç³»ç»Ÿ"""
        if self.camera_thread:
            try:
                self.camera_thread.stop()
                self.camera_thread = None
            except Exception as e:
                print(f"åœæ­¢ç›¸æœºçº¿ç¨‹æ—¶å‡ºé”™: {e}")
        
        # æ›´æ–°UIçŠ¶æ€
        self.start_btn.setText("å¯åŠ¨ç³»ç»Ÿ")
        self.start_btn.setStyleSheet("background-color: #4CAF50; color: white; font-weight: bold;")
        
        # æ¸…ç©ºè§†é¢‘æ˜¾ç¤º
        self.video_label.clear()
        self.video_label.setText("ç³»ç»Ÿå·²åœæ­¢")
        
        # æ›´æ–°çŠ¶æ€
        self.camera_status.setText("æœªè¿æ¥")
        self.camera_status.setStyleSheet("color: red; font-weight: bold;")
        self.model_status.setText("æœªåŠ è½½")
        self.model_status.setStyleSheet("color: red; font-weight: bold;")
        self.uart_rx_status.setText("æœªè¿æ¥")
        self.uart_tx_status.setText("æœªè¿æ¥")
        self.long_status_label.setText("ç©ºé—²")
        self.long_status_label.setStyleSheet("color: green; font-weight: bold;")
        self.long_status_small.setText("ç©ºé—²")
        self.long_status_small.setStyleSheet("color: green; font-weight: bold;")
        self.count_line_label.setText("0 px (0.0%)")
        self.roi_label.setText("å…¨å±")
        self.downsample_label.setText("1.0x")
        self.counting_direction_label.setText("å‘ä¸‹")
        
        self.log_event("ç³»ç»Ÿå·²åœæ­¢")
    
    def update_video_display(self, frame, stats):
        """æ›´æ–°è§†é¢‘æ˜¾ç¤ºï¼Œç¡®ä¿ä¸ä¼šè¶…å‡ºå±å¹•"""
        try:
            # ä¿å­˜åŸå§‹å¸§å°ºå¯¸
            self.video_height, self.video_width = frame.shape[:2]
            
            # è½¬æ¢OpenCVå¸§ä¸ºQtå›¾åƒ
            height, width, channel = frame.shape
            bytes_per_line = 3 * width
            q_img = QImage(frame.data, width, height, bytes_per_line, QImage.Format_RGB888).rgbSwapped()
            
            # åˆ›å»ºPixmapå¹¶ä¿å­˜
            self.current_pixmap = QPixmap.fromImage(q_img)
            
            if self.fit_to_window:
                # è·å–å½“å‰å¯ç”¨ç©ºé—´ï¼ˆè€ƒè™‘æ»šåŠ¨åŒºåŸŸå’Œè¾¹è·ï¼‰
                scroll_widget = self.video_container.parentWidget()
                if scroll_widget:
                    # è·å–æ»šåŠ¨åŒºåŸŸçš„å¯ç”¨å¤§å°
                    scroll_area = scroll_widget.parentWidget()
                    if scroll_area:
                        available_width = scroll_area.width() - 30  # å‡å»æ»šåŠ¨æ¡å®½åº¦å’Œè¾¹è·
                        available_height = scroll_area.height() - 50  # å‡å»çŠ¶æ€æ ‡ç­¾å’Œè¾¹è·
                    else:
                        available_width = self.video_label.width()
                        available_height = self.video_label.height()
                else:
                    available_width = self.video_label.width()
                    available_height = self.video_label.height()
                
                # ç¡®ä¿å¯ç”¨å°ºå¯¸æœ‰æ•ˆ
                available_width = max(100, available_width)
                available_height = max(100, available_height)
                
                # å…³é”®æ”¹è¿›ï¼šç‹¬ç«‹æ£€æŸ¥å®½åº¦å’Œé«˜åº¦æ˜¯å¦è¶…å‡ºï¼Œè€Œä¸æ˜¯ç»Ÿä¸€ç¼©æ”¾
                
                # åˆå§‹å€¼
                new_width = width
                new_height = height
                
                # æ£€æŸ¥å®½åº¦æ˜¯å¦è¶…å‡ºå¯ç”¨å®½åº¦
                if width > available_width:
                    # å®½åº¦è¶…å‡ºï¼ŒæŒ‰å®½åº¦ç¼©æ”¾
                    scale_w = available_width / width
                    new_width = available_width
                    new_height = int(height * scale_w)
                
                # æ£€æŸ¥ç¼©æ”¾åçš„é«˜åº¦æ˜¯å¦è¶…å‡ºå¯ç”¨é«˜åº¦
                if new_height > available_height:
                    # é«˜åº¦è¶…å‡ºï¼ŒæŒ‰é«˜åº¦ç¼©æ”¾
                    scale_h = available_height / new_height
                    new_height = available_height
                    new_width = int(new_width * scale_h)
                
                # åº”ç”¨æœ€ç»ˆçš„ç¼©æ”¾
                if new_width != width or new_height != height:
                    # éœ€è¦ç¼©æ”¾
                    scaled_pixmap = self.current_pixmap.scaled(
                        new_width, new_height, 
                        Qt.KeepAspectRatio,  # ä¿æŒå®½é«˜æ¯”
                        Qt.SmoothTransformation
                    )
                    self.video_label.setPixmap(scaled_pixmap)
                    
                    # è®¡ç®—å®é™…çš„ç¼©æ”¾æ¯”ä¾‹
                    actual_scale_w = new_width / width
                    actual_scale_h = new_height / height
                    actual_scale = min(actual_scale_w, actual_scale_h)
                    
                    self.size_label.setText(f"æ˜¾ç¤ºå°ºå¯¸: {new_width}x{new_height} (ç¼©æ”¾: {actual_scale:.2f}x)")
                else:
                    # ä¸éœ€è¦ç¼©æ”¾ï¼Œæ˜¾ç¤ºåŸå§‹å¤§å°
                    self.video_label.setPixmap(self.current_pixmap)
                    self.size_label.setText(f"åŸå§‹å°ºå¯¸: {width}x{height}")
                
            else:
                # æ˜¾ç¤ºæ¨¡å¼ï¼šåŸå§‹å¤§å°
                self.video_label.setPixmap(self.current_pixmap)
                self.video_label.adjustSize()
                self.size_label.setText(f"åŸå§‹å°ºå¯¸: {width}x{height} (åŸå§‹å¤§å°)")
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.stats = stats
            
        except Exception as e:
            print(f"æ›´æ–°è§†é¢‘æ˜¾ç¤ºæ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
    
    def toggle_display_mode(self):
        """åˆ‡æ¢æ˜¾ç¤ºæ¨¡å¼"""
        self.fit_to_window = not self.fit_to_window
        if self.fit_to_window:
            self.display_mode_btn.setText("é€‚åº”çª—å£")
            self.display_mode_btn.setStyleSheet("background-color: #4CAF50; color: white;")
        else:
            self.display_mode_btn.setText("åŸå§‹å¤§å°")
            self.display_mode_btn.setStyleSheet("background-color: #2196F3; color: white;")
        
        # ç«‹å³é‡æ–°æ˜¾ç¤ºå½“å‰å¸§
        if hasattr(self, 'current_pixmap') and self.current_pixmap:
            self.update_video_display_from_cache()
    
    def show_original_size(self):
        """æ˜¾ç¤ºåŸå§‹å¤§å°"""
        self.fit_to_window = False
        self.display_mode_btn.setText("åŸå§‹å¤§å°")
        self.display_mode_btn.setStyleSheet("background-color: #2196F3; color: white;")
        
        if hasattr(self, 'current_pixmap') and self.current_pixmap:
            self.video_label.setPixmap(self.current_pixmap)
            self.video_label.adjustSize()
            pixmap_size = self.current_pixmap.size()
            self.size_label.setText(f"åŸå§‹å°ºå¯¸: {pixmap_size.width()}x{pixmap_size.height()}")
    
    def update_video_display_from_cache(self):
        """ä»ç¼“å­˜çš„Pixmapæ›´æ–°æ˜¾ç¤º"""
        if hasattr(self, 'current_pixmap') and self.current_pixmap:
            if self.fit_to_window:
                # é‡æ–°è®¡ç®—é€‚åº”çª—å£çš„æ˜¾ç¤º
                pixmap_size = self.current_pixmap.size()
                width = pixmap_size.width()
                height = pixmap_size.height()
                
                # è·å–å½“å‰å¯ç”¨ç©ºé—´
                scroll_widget = self.video_container.parentWidget()
                if scroll_widget:
                    scroll_area = scroll_widget.parentWidget()
                    if scroll_area:
                        available_width = scroll_area.width() - 30
                        available_height = scroll_area.height() - 50
                    else:
                        available_width = self.video_label.width()
                        available_height = self.video_label.height()
                else:
                    available_width = self.video_label.width()
                    available_height = self.video_label.height()
                
                # ç¡®ä¿æœ‰æ•ˆå°ºå¯¸
                available_width = max(100, available_width)
                available_height = max(100, available_height)
                
                # ç‹¬ç«‹çš„å®½é«˜æ£€æŸ¥
                new_width = width
                new_height = height
                
                if width > available_width:
                    scale_w = available_width / width
                    new_width = available_width
                    new_height = int(height * scale_w)
                
                if new_height > available_height:
                    scale_h = available_height / new_height
                    new_height = available_height
                    new_width = int(new_width * scale_h)
                
                # åº”ç”¨ç¼©æ”¾
                if new_width != width or new_height != height:
                    scaled_pixmap = self.current_pixmap.scaled(
                        new_width, new_height, 
                        Qt.KeepAspectRatio, 
                        Qt.SmoothTransformation
                    )
                    self.video_label.setPixmap(scaled_pixmap)
                    
                    actual_scale_w = new_width / width
                    actual_scale_h = new_height / height
                    actual_scale = min(actual_scale_w, actual_scale_h)
                    
                    self.size_label.setText(f"æ˜¾ç¤ºå°ºå¯¸: {new_width}x{new_height} (ç¼©æ”¾: {actual_scale:.2f}x)")
                else:
                    self.video_label.setPixmap(self.current_pixmap)
                    self.size_label.setText(f"åŸå§‹å°ºå¯¸: {width}x{height}")
            else:
                # åŸå§‹å¤§å°æ¨¡å¼
                self.video_label.setPixmap(self.current_pixmap)
                self.video_label.adjustSize()
                pixmap_size = self.current_pixmap.size()
                self.size_label.setText(f"åŸå§‹å°ºå¯¸: {pixmap_size.width()}x{pixmap_size.height()}")
    
    def resizeEvent(self, event):
        """çª—å£å¤§å°æ”¹å˜æ—¶è°ƒæ•´è§†é¢‘æ˜¾ç¤º"""
        super().resizeEvent(event)
        
        # å¦‚æœå½“å‰æ˜¯é€‚åº”çª—å£æ¨¡å¼ï¼Œé‡æ–°è®¡ç®—æ˜¾ç¤ºå°ºå¯¸
        if self.fit_to_window and hasattr(self, 'current_pixmap') and self.current_pixmap:
            # ä½¿ç”¨å®šæ—¶å™¨å»¶è¿Ÿæ›´æ–°ï¼Œé¿å…é¢‘ç¹é‡ç»˜
            QTimer.singleShot(100, self.update_video_display_from_cache)
    
    def update_status(self):
        """æ›´æ–°çŠ¶æ€ä¿¡æ¯"""
        if self.camera_thread and self.camera_thread.running:
            # æ›´æ–°è¿è¡Œæ—¶é—´
            if hasattr(self, 'start_time'):
                uptime = int(time.time() - self.start_time)
                hours = uptime // 3600
                minutes = (uptime % 3600) // 60
                seconds = uptime % 60
                self.uptime_label.setText(f"{hours:02d}:{minutes:02d}:{seconds:02d}")
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            if hasattr(self, 'stats'):
                self.fps_label.setText(str(self.stats.get('fps', 0)))
                self.detections_label.setText(str(self.stats.get('detections', 0)))
                self.tracked_label.setText(str(self.stats.get('tracked', 0)))
                self.counted_label.setText(str(self.stats.get('counted', 0)))
                
                # ä½å¯†åº¦çŠ¶æ€
                low_density = self.stats.get('low_density', False)
                self.low_density_label.setText("ä½å¯†åº¦" if low_density else "æ­£å¸¸")
                self.low_density_label.setStyleSheet(
                    "color: orange; font-weight: bold;" if low_density else "color: green; font-weight: bold;"
                )
                
                # é—¨æ§çŠ¶æ€
                gate_state = self.stats.get('gate_state', False)
                self.gate_label.setText("å¼€å¯" if gate_state else "å…³é—­")
                self.gate_label.setStyleSheet(
                    "color: green; font-weight: bold;" if gate_state else "color: red; font-weight: bold;"
                )
                
                # é€Ÿåº¦å’Œä½ç½®
                self.speed_label.setText(f"{self.stats.get('v_mmps', 0)} mm/s")
                self.position_label.setText(f"{self.stats.get('s_mm', 0)} mm")
                
                # UARTçŠ¶æ€
                self.uart_rx_status.setText(self.stats.get('uart_rx_status', 'æœªè¿æ¥'))
                self.uart_tx_status.setText(self.stats.get('uart_tx_status', 'æœªè¿æ¥'))
                
                # æ›´æ–°çŠ¶æ€é¢œè‰²
                rx_color = "green" if self.stats.get('uart_rx_status') == 'è¿è¡Œä¸­' else "red"
                tx_color = "green" if self.stats.get('uart_tx_status') == 'è¿è¡Œä¸­' else "red"
                self.uart_rx_status.setStyleSheet(f"color: {rx_color}; font-weight: bold;")
                self.uart_tx_status.setStyleSheet(f"color: {tx_color}; font-weight: bold;")

                # é•¿å›¾çŠ¶æ€
                long_text = self.stats.get('long_status', 'ç©ºé—²')
                self.long_status_small.setText(long_text)
                self.long_status_label.setText(long_text)
                color = "green" if long_text == "ç©ºé—²" else "orange"
                self.long_status_small.setStyleSheet(f"color: {color}; font-weight: bold;")
                self.long_status_label.setStyleSheet(f"color: {color}; font-weight: bold;")
                
                # è®¡æ•°çº¿å’ŒROIçŠ¶æ€
                count_line_y = self.stats.get('count_line_y', 0)
                count_line_percent = 0
                if count_line_y > 0 and self.camera_thread and hasattr(self.camera_thread, 'original_frame_height'):
                    count_line_percent = (count_line_y / self.camera_thread.original_frame_height) * 100
                self.count_line_label.setText(f"{count_line_y} px ({count_line_percent:.1f}%)")
                
                roi_info = self.stats.get('roi_info', 'å…¨å±')
                self.roi_label.setText(roi_info)
                
                # ä¸‹é‡‡æ ·çŠ¶æ€
                self.downsample_label.setText(f"{self.downsample_ratio:.2f}x")
                
                # è®¡æ•°æ–¹å‘
                self.counting_direction_label.setText(self.direction_combo.currentText())
        
        # æ›´æ–°çŠ¶æ€æ 
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        self.status_label.setText(f"å°±ç»ª | {current_time}")
    
    def toggle_recording(self):
        """åˆ‡æ¢å½•åˆ¶çŠ¶æ€"""
        if self.record_btn.text() == "å¼€å§‹å½•åˆ¶":
            self.record_btn.setText("åœæ­¢å½•åˆ¶")
            self.record_btn.setStyleSheet("background-color: #f44336; color: white;")
            self.log_event("å¼€å§‹å½•åˆ¶è§†é¢‘")
        else:
            self.record_btn.setText("å¼€å§‹å½•åˆ¶")
            self.record_btn.setStyleSheet("")
            self.log_event("åœæ­¢å½•åˆ¶è§†é¢‘")
    
    def take_snapshot(self):
        """æˆªå›¾"""
        if self.camera_thread and self.camera_thread.running:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = os.path.join(self.base_save_dir, f"snapshot_{timestamp}.jpg")
            try:
                # ä¿å­˜å½“å‰æ˜¾ç¤ºçš„è§†é¢‘å¸§
                if hasattr(self, 'current_pixmap') and self.current_pixmap:
                    self.current_pixmap.save(filename, "JPG")
                    self.log_event(f"æˆªå›¾å·²ä¿å­˜: {filename}")
                else:
                    self.log_event("æˆªå›¾å¤±è´¥ï¼šæ— å¯ç”¨å›¾åƒ")
            except Exception as e:
                self.log_event(f"æˆªå›¾å¤±è´¥: {e}")
    
    def clear_counting(self):
        """æ¸…é›¶è®¡æ•°"""
        if self.camera_thread:
            self.camera_thread.counted_objects.clear()
            self.camera_thread.stats['counted'] = 0
            self.log_event("è®¡æ•°å·²æ¸…é›¶")
    
    def clear_log(self):
        """æ¸…ç©ºæ—¥å¿—"""
        self.log_text.clear()
    
    def log_event(self, message):
        """è®°å½•äº‹ä»¶åˆ°æ—¥å¿—"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] {message}"
        self.log_text.append(log_entry)
        
        # è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
        self.log_text.verticalScrollBar().setValue(
            self.log_text.verticalScrollBar().maximum()
        )
    
    def closeEvent(self, event):
        """å…³é—­çª—å£äº‹ä»¶"""
        if self.camera_thread and self.camera_thread.running:
            reply = QMessageBox.question(self, "ç¡®è®¤", 
                                        "ç³»ç»Ÿæ­£åœ¨è¿è¡Œï¼Œç¡®å®šè¦é€€å‡ºå—?",
                                        QMessageBox.Yes | QMessageBox.No)
            if reply == QMessageBox.Yes:
                self.stop_system()
                event.accept()
            else:
                event.ignore()
        else:
            event.accept()

    # ===== é•¿å›¾æ‰‹åŠ¨æ§åˆ¶ =====
    def manual_start_long(self):
        if not (self.camera_thread and self.camera_thread.running):
            return
        if self.camera_thread.enable_uart_rx and SERIAL_AVAILABLE:
            QMessageBox.information(self, "æç¤º", "UART å¼€å¯æ—¶ç”±é€Ÿåº¦è‡ªåŠ¨æ§åˆ¶ï¼Œä¸æ”¯æŒæ‰‹åŠ¨ã€‚")
            return
        self.camera_thread.start_manual_long_capture()
        self.log_event("æ‰‹åŠ¨å¼€å§‹é•¿å›¾æ‹¼æ¥")

    def manual_stop_long(self):
        if not (self.camera_thread and self.camera_thread.running):
            return
        if self.camera_thread.enable_uart_rx and SERIAL_AVAILABLE:
            QMessageBox.information(self, "æç¤º", "UART å¼€å¯æ—¶ç”±é€Ÿåº¦è‡ªåŠ¨æ§åˆ¶ï¼Œä¸æ”¯æŒæ‰‹åŠ¨ã€‚")
            return
        self.camera_thread.stop_manual_long_capture()
        self.log_event("æ‰‹åŠ¨ç»“æŸé•¿å›¾æ‹¼æ¥å¹¶è¯†åˆ«")

    def on_long_status_changed(self, text):
        self.long_status_label.setText(text)
        self.long_status_small.setText(text)
        color = "green" if text == "ç©ºé—²" else "orange"
        self.long_status_label.setStyleSheet(f"color: {color}; font-weight: bold;")
        self.long_status_small.setStyleSheet(f"color: {color}; font-weight: bold;")

    # ===== é”®ç›˜å¿«æ·é”® =====
    def keyPressEvent(self, event):
        key_text = event.text().upper()
        if not key_text:
            return super().keyPressEvent(event)
        if not (self.camera_thread and self.camera_thread.running):
            return super().keyPressEvent(event)
        # ä»…åœ¨ UART å…³é—­æˆ–ä¸å¯ç”¨æ—¶å…è®¸å¿«æ·é”®
        if self.camera_thread.enable_uart_rx and SERIAL_AVAILABLE:
            return super().keyPressEvent(event)
        if key_text == self.hotkey_start:
            self.manual_start_long()
            return
        if key_text == self.hotkey_stop:
            self.manual_stop_long()
            return
        return super().keyPressEvent(event)


# ===== ä¸»ç¨‹åº =====
def main():
    print("ğŸ¯ seedyolo.pyï¼šæ—¶é—´å¯¹é½ + é—¨æ§è¯†åˆ« + è®¡æ•° + å¯†åº¦åŒºé—´ç¼“å­˜ + å…‹é‡æ¢ç®— + UIç•Œé¢")
    print(f"ğŸ”§ æ”¯æŒYOLO26æ¨¡å‹ï¼ŒNMSå¼€å…³: {'å¯ç”¨' if USE_NMS_FOR_YOLO26 else 'ç¦ç”¨'}")
    print(f"ğŸ”§ æœ€å¤§æ£€æµ‹æ•°é‡: {MAX_DETECTIONS}")
    print(f"ğŸ”§ é»˜è®¤æ¨¡å‹è·¯å¾„: {DEFAULT_MODEL_PATH}")
    print(f"ğŸ”§ æˆªå›¾ä¿å­˜è·¯å¾„: {DEFAULT_SAVE_DIR}")
    print(f"ğŸ”§ è®¡æ•°çº¿ä½ç½®: {COUNT_LINE_PERCENT_DEFAULT}%")
    print(f"ğŸ”§ ROIæ‰©å±•: ä¸Š{COUNT_LINE_TOP_EXTEND_DEFAULT}px, ä¸‹{COUNT_LINE_BOTTOM_EXTEND_DEFAULT}px")
    print(f"ğŸ”§ ä¸‹é‡‡æ ·æ¯”ä¾‹: {DOWNSAMPLE_RATIO_DEFAULT}")
    print(f"ğŸ”§ è®¡æ•°æ¨¡å¼: å¯ç”¨æ—¶åªè¯†åˆ«ROIåŒºåŸŸï¼Œç¦ç”¨æ—¶å…¨å±è¯†åˆ«")
    print(f"ğŸ”§ æ–°å¢åŠŸèƒ½: ç¨‹åºå…¨å±æˆªå±ï¼Œä¿å­˜è·¯å¾„å¯é…ç½®")
    
    # æ£€æŸ¥PyQt5æ˜¯å¦å¯ç”¨
    if not PYQT_AVAILABLE:
        print("âŒ PyQt5ä¸å¯ç”¨ï¼Œæ— æ³•å¯åŠ¨UIç•Œé¢")
        print("è¯·å®‰è£…: pip install PyQt5")
        return
    
    # åˆ›å»ºåº”ç”¨
    app = QApplication(sys.argv)
    app.setStyle('Fusion')  # ä½¿ç”¨Fusionæ ·å¼
    
    # åˆ›å»ºå¹¶æ˜¾ç¤ºä¸»çª—å£
    window = MainWindow()
    window.show()
    
    # å¯åŠ¨åº”ç”¨
    sys.exit(app.exec_())


if __name__ == "__main__":
    main()
